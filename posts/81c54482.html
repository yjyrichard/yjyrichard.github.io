<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><div id="myscoll"></div><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习期末设计 | Yangjiayu</title><meta name="keywords" content="机器学习"><meta name="author" content="Yangjiayu"><meta name="copyright" content="Yangjiayu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="预测锻炼期间燃烧卡路里的数据分析与建模">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习期末设计">
<meta property="og:url" content="https://yjyrichard.github.io/posts/81c54482.html">
<meta property="og:site_name" content="Yangjiayu">
<meta property="og:description" content="预测锻炼期间燃烧卡路里的数据分析与建模">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/2.png">
<meta property="article:published_time" content="2025-05-28T05:16:50.378Z">
<meta property="article:modified_time" content="2025-05-29T12:19:57.874Z">
<meta property="article:author" content="Yangjiayu">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/2.png"><link rel="shortcut icon" href="https://bilibili123.oss-cn-beijing.aliyuncs.com/about/your_image_path_here.jpg"><link rel="canonical" href="https://yjyrichard.github.io/posts/81c54482"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"var(--theme-color)","bgDark":"#191919","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习期末设计',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-05-29 20:19:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><style id="themeColor"></style><style id="rightSide"></style><style id="transPercent"></style><style id="blurNum"></style><style id="settingStyle"></style><span id="fps"></span><style id="defineBg"></style><style id="menu_shadow"></style><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Yangjiayu" type="application/atom+xml">
</head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/about/your_image_path_here.jpg" onerror="onerror=null;src='/assets/r1.jpg'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">70</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pinweishenghuo"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-yinle">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying1">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-youxishoubing">                   </use></svg><span class="menu_word" style="font-size:17px"> 健身</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/books/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 时间管理</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-love-sign">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yangjiayu</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pinweishenghuo"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-yinle">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying1">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-youxishoubing">                   </use></svg><span class="menu_word" style="font-size:17px"> 健身</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/books/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 时间管理</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-love-sign">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="search faa-parent animated-hover" title="检索站内任何你想要的信息"><svg class="faa-tada icon" style="height:24px;width:24px;fill:currentColor;position:relative;top:6px" aria-hidden="true"><use xlink:href="#icon-valentine_-search-love-find-heart"></use></svg><span> 搜索</span></a></div><a class="meihua faa-parent animated-hover" onclick="toggleWinbox()" title="美化设置-自定义你的风格" id="meihua-button"><svg class="faa-tada icon" style="height:26px;width:26px;fill:currentColor;position:relative;top:8px" aria-hidden="true"><use xlink:href="#icon-tupian1"></use></svg></a><a class="sun_moon faa-parent animated-hover" onclick="switchNightMode()" title="浅色和深色模式转换" id="nightmode-button"><svg class="faa-tada" style="height:25px;width:25px;fill:currentColor;position:relative;top:7px" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon">       </use></svg></a><div id="toggle-menu"><a><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-info"><h1 class="post-title">机器学习期末设计</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于 </span><time class="post-meta-date-created" datetime="2025-05-28T05:16:50.378Z" title="发表于 2025-05-28 13:16:50">2025-05-28</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-29T12:19:57.874Z" title="更新于 2025-05-29 20:19:57">2025-05-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">2.4w</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>107分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习期末设计"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>预测锻炼期间燃烧卡路里的数据分析与建模</h1>
<h2 id="一、确定业务目标">一、确定业务目标</h2>
<p>本项目旨在通过分析锻炼相关数据，建立模型预测锻炼期间燃烧的卡路里量。这项研究具有重要的现实意义：</p>
<ol>
<li><strong>个性化健康管理</strong>：准确预测卡路里消耗可以帮助个人调整锻炼计划，达到健康减重或保持体重的目标。</li>
<li><strong>健身效果评估</strong>：为健身爱好者提供量化的锻炼效果评估，优化锻炼方案。</li>
<li><strong>智能健康设备开发</strong>：为智能手环、手表等健康监测设备提供更准确的卡路里消耗算法。</li>
<li><strong>健康应用支持</strong>：为健康和健身应用提供更精准的能量消耗预测功能。</li>
</ol>
<p>本项目的具体目标是：</p>
<ul>
<li>分析各项身体指标和运动特征与卡路里消耗的关系</li>
<li>构建高精度的卡路里消耗预测模型</li>
<li>评估不同机器学习算法的预测效果</li>
<li>提供可用于实际应用的预测模型</li>
</ul>
<h2 id="二、获取数据">二、获取数据</h2>
<p>数据来源于Kaggle平台的&quot;Calories Burnt Prediction&quot;数据集。该数据集包含以下文件：</p>
<ol>
<li><strong>train.csv</strong>：训练数据集，包含锻炼相关特征和卡路里消耗量</li>
<li><strong>test.csv</strong>：测试数据集，包含锻炼相关特征，需要预测卡路里消耗量</li>
<li><strong>sample_submission.csv</strong>：提交格式样例</li>
</ol>
<p>数据集包含以下特征：</p>
<ul>
<li><strong>id</strong>：记录ID</li>
<li><strong>Sex</strong>：性别（male/female）</li>
<li><strong>Age</strong>：年龄</li>
<li><strong>Height</strong>：身高（厘米）</li>
<li><strong>Weight</strong>：体重（千克）</li>
<li><strong>Duration</strong>：锻炼持续时间（分钟）</li>
<li><strong>Heart_Rate</strong>：心率（次/分钟）</li>
<li><strong>Body_Temp</strong>：体温（摄氏度）</li>
<li><strong>Calories</strong>：燃烧的卡路里（仅在训练集中提供）</li>
</ul>
<p>这个是一个当前正在举办的比赛，地址：<a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/playground-series-s5e5/overview">Predict Calorie Expenditure | Kaggle</a></p>
<h2 id="三、数据预处理和探索性分析">三、数据预处理和探索性分析</h2>
<h3 id="3-1-数据预处理">3.1 数据预处理</h3>
<p>数据预处理阶段包括以下步骤：</p>
<ol>
<li>
<p><strong>数据加载与检查</strong>：</p>
<ul>
<li>加载训练和测试数据集</li>
<li>检查数据集大小和基本信息</li>
<li>查看数据类型和统计摘要</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 1. 数据获取</span></span><br><span class="line">train_data, test_data = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 数据预处理</span></span><br><span class="line">train_data = preprocess_data(train_data)</span><br><span class="line">test_data = preprocess_data(test_data, is_train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载训练集和测试集数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (训练数据, 测试数据)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在加载数据...&quot;</span>)</span><br><span class="line">        train_data = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">        test_data = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;训练集大小：<span class="subst">&#123;train_data.shape&#125;</span>, 测试集大小：<span class="subst">&#123;test_data.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> train_data, test_data</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;加载数据时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528101850943.png" alt="image-20250528101850943"></p>
<p>读取这个数据的前五行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示前五行</span></span><br><span class="line"><span class="built_in">print</span>(train_data.head())</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528101622498.png" alt="image-20250528101622498"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;正在进行数据预处理...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据副本，避免修改原始数据</span></span><br><span class="line">df = data.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示数据基本信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n数据基本信息:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.info())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示数据统计摘要</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n数据统计摘要:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.describe())</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528102208243.png" alt="image-20250528102208243"></p>
</li>
<li>
<p><strong>缺失值处理</strong>：</p>
<ul>
<li>检查各特征的缺失值</li>
<li>使用适当的方法填充缺失值（若有）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查缺失值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n检查缺失值:&quot;</span>)</span><br><span class="line">missing_values = df.isnull().<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(missing_values[missing_values &gt; <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理缺失值（如果有）</span></span><br><span class="line"><span class="keyword">if</span> df.isnull().<span class="built_in">sum</span>().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 对数值型特征使用均值填充，分类特征使用众数填充</span></span><br><span class="line">    num_features = df.select_dtypes(include=[<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]).columns</span><br><span class="line">    cat_features = df.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> num_features:</span><br><span class="line">        <span class="keyword">if</span> df[col].isnull().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">            df[col].fillna(df[col].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> cat_features:</span><br><span class="line">        <span class="keyword">if</span> df[col].isnull().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">            df[col].fillna(df[col].mode()[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>特征编码</strong>：</p>
<ul>
<li>将分类特征（如性别）编码为数值形式</li>
<li>男性编码为1，女性编码为0</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 性别编码：将性别特征转换为数值</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;Sex&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">    df[<span class="string">&#x27;Sex&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除ID列，因为它不是预测的特征</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;id&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">    df = df.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示处理后的数据信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n预处理后的数据信息:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.info())</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528103836338.png" alt="image-20250528103836338"></p>
</li>
<li>
<p><strong>特征工程</strong>：</p>
<ul>
<li>使用StandardScaler对数值特征进行标准化处理（模型训练和评估当中）</li>
<li>使模型训练更稳定，提高收敛速度</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征工程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_engineering</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建新特征以提高模型性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 预处理后的数据</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        DataFrame: 包含新特征的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行特征工程...&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程前数据形状: <span class="subst">&#123;data.shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建数据副本</span></span><br><span class="line">        df = data.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录原始特征列表</span></span><br><span class="line">        original_features = df.columns.tolist()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 创建BMI特征（体重指数）</span></span><br><span class="line">        df[<span class="string">&#x27;BMI&#x27;</span>] = df[<span class="string">&#x27;Weight&#x27;</span>] / ((df[<span class="string">&#x27;Height&#x27;</span>]/<span class="number">100</span>) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 创建心率与年龄的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Heart_Rate_Age_Ratio&#x27;</span>] = df[<span class="string">&#x27;Heart_Rate&#x27;</span>] / df[<span class="string">&#x27;Age&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 创建锻炼强度指标</span></span><br><span class="line">        df[<span class="string">&#x27;Exercise_Intensity&#x27;</span>] = df[<span class="string">&#x27;Heart_Rate&#x27;</span>] * df[<span class="string">&#x27;Duration&#x27;</span>] / <span class="number">100</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 创建体温与心率的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Temp_Heart_Ratio&#x27;</span>] = df[<span class="string">&#x27;Body_Temp&#x27;</span>] / df[<span class="string">&#x27;Heart_Rate&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 体重与身高的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Weight_Height_Ratio&#x27;</span>] = df[<span class="string">&#x27;Weight&#x27;</span>] / (df[<span class="string">&#x27;Height&#x27;</span>]/<span class="number">100</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取新创建的特征列表</span></span><br><span class="line">        new_features = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> original_features]</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程完成，创建了 <span class="subst">&#123;<span class="built_in">len</span>(new_features)&#125;</span> 个新特征:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> new_features:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  - <span class="subst">&#123;feature&#125;</span>: 均值=<span class="subst">&#123;df[feature].mean():<span class="number">.4</span>f&#125;</span>, 标准差=<span class="subst">&#123;df[feature].std():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程后数据形状: <span class="subst">&#123;df.shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> df</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528104847152.png" alt="image-20250528104847152"></p>
<h3 id="3-2-探索性数据分析">3.2 探索性数据分析</h3>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 探索性数据分析</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exploratory_data_analysis</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    进行探索性数据分析</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 需要分析的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行探索性数据分析...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建保存图形的文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;plots&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;plots&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 对于大数据集，可以使用采样减少计算量</span></span><br><span class="line">        sample_size = <span class="built_in">min</span>(<span class="number">10000</span>, <span class="built_in">len</span>(data))</span><br><span class="line">        data_sample = data.sample(n=sample_size, random_state=<span class="number">42</span>) <span class="keyword">if</span> <span class="built_in">len</span>(data) &gt; <span class="number">10000</span> <span class="keyword">else</span> data</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;使用<span class="subst">&#123;<span class="string">&#x27;采样数据&#x27;</span> <span class="keyword">if</span> <span class="built_in">len</span>(data) &gt; <span class="number">10000</span> <span class="keyword">else</span> <span class="string">&#x27;完整数据&#x27;</span>&#125;</span>进行可视化分析，样本大小: <span class="subst">&#123;<span class="built_in">len</span>(data_sample)&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分阶段执行可视化</span></span><br><span class="line">        plot_basic_distributions(data_sample)</span><br><span class="line">        plot_correlations(data_sample)</span><br><span class="line">        plot_feature_relationships(data_sample)</span><br><span class="line">        plot_categorical_analysis(data_sample)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;探索性数据分析完成，图表已保存到 &#x27;plots&#x27; 文件夹&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;探索性数据分析过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure>
<p>探索性数据分析阶段包括以下内容：</p>
<ol>
<li>
<p><strong>目标变量分析</strong>：</p>
<ul>
<li>卡路里消耗的分布情况</li>
<li>异常值检测</li>
</ul>
</li>
<li>
<p><strong>特征分析</strong>：</p>
<ul>
<li>各特征的分布情况</li>
<li>箱线图检查异常值</li>
</ul>
</li>
<li>
<p><strong>相关性分析</strong>：</p>
<ul>
<li>特征间的相关性热力图</li>
<li>各特征与卡路里消耗的相关性</li>
</ul>
</li>
<li>
<p><strong>特征与目标变量的关系</strong>：</p>
<ul>
<li>各特征与卡路里消耗的散点图</li>
<li>性别对卡路里消耗的影响</li>
<li>年龄与卡路里消耗的关系</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_basic_distributions</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制基本分布图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成基本分布图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 目标变量分布</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.histplot(data[<span class="string">&#x27;Calories&#x27;</span>], kde=<span class="literal">True</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;卡路里消耗分布&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;卡路里&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;频率&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/calories_distribution.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 特征分布图（在一个图中展示所有数值特征）</span></span><br><span class="line">        numerical_features = data.select_dtypes(include=[<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]).columns</span><br><span class="line">        numerical_features = [col <span class="keyword">for</span> col <span class="keyword">in</span> numerical_features <span class="keyword">if</span> col != <span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        fig, axes = plt.subplots(nrows=(<span class="built_in">len</span>(numerical_features)//<span class="number">3</span>) + (<span class="number">1</span> <span class="keyword">if</span> <span class="built_in">len</span>(numerical_features)%<span class="number">3</span> &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>), </span><br><span class="line">                                ncols=<span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">3</span>*((<span class="built_in">len</span>(numerical_features)//<span class="number">3</span>) + (<span class="number">1</span> <span class="keyword">if</span> <span class="built_in">len</span>(numerical_features)%<span class="number">3</span> &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>))))</span><br><span class="line">        axes = axes.flatten()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, feature <span class="keyword">in</span> <span class="built_in">enumerate</span>(numerical_features):</span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(axes):</span><br><span class="line">                sns.histplot(data[feature], kde=<span class="literal">True</span>, ax=axes[i])</span><br><span class="line">                axes[i].set_title(<span class="string">f&#x27;<span class="subst">&#123;feature&#125;</span> 分布&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 隐藏未使用的子图</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, <span class="built_in">len</span>(axes)):</span><br><span class="line">            axes[j].set_visible(<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/feature_distributions.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;基本分布图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成基本分布图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/calories_distribution.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/feature_distributions.png" alt=""></p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_correlations</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制相关性分析图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成相关性分析图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 相关性热力图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</span><br><span class="line">        correlation_matrix = data.corr()</span><br><span class="line">        sns.heatmap(correlation_matrix, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, fmt=<span class="string">&#x27;.2f&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;特征相关性热力图&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/correlation_heatmap.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征与目标变量的相关性条形图</span></span><br><span class="line">        correlations = data.corr()[<span class="string">&#x27;Calories&#x27;</span>].drop(<span class="string">&#x27;Calories&#x27;</span>).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">        sns.barplot(x=correlations.values, y=correlations.index)</span><br><span class="line">        plt.title(<span class="string">&#x27;特征与卡路里消耗的相关性&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;相关系数&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/feature_target_correlation.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;相关性分析图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成相关性分析图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528105807741.png" alt="image-20250528105807741"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528110104710.png" alt="image-20250528110104710"></p>
<p>发现新特征没啥用，后续训练模型的时候也就没使用这些新的特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_feature_relationships</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制特征关系图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成特征关系图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 只为相关性最高的前5个特征生成散点图</span></span><br><span class="line">        correlation_with_target = data.corr()[<span class="string">&#x27;Calories&#x27;</span>].<span class="built_in">abs</span>().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">        top_features = correlation_with_target.index[<span class="number">1</span>:<span class="number">6</span>]  <span class="comment"># 排除Calories自身</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> tqdm(top_features, desc=<span class="string">&quot;生成特征散点图&quot;</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">                sns.scatterplot(x=feature, y=<span class="string">&#x27;Calories&#x27;</span>, data=data, hue=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">                plt.title(<span class="string">f&#x27;<span class="subst">&#123;feature&#125;</span> 与卡路里消耗的关系&#x27;</span>)</span><br><span class="line">                plt.savefig(<span class="string">f&#x27;plots/<span class="subst">&#123;feature&#125;</span>_vs_calories.png&#x27;</span>)</span><br><span class="line">                plt.close()</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;  生成 <span class="subst">&#123;feature&#125;</span> 散点图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                plt.close()</span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># 继续处理下一个特征</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成一个包含所有重要特征的配对图</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;正在生成特征配对图（这可能需要一些时间）...&quot;</span>)</span><br><span class="line">            sns.pairplot(data[<span class="built_in">list</span>(top_features) + [<span class="string">&#x27;Calories&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>]], </span><br><span class="line">                        hue=<span class="string">&#x27;Sex&#x27;</span>, </span><br><span class="line">                        diag_kind=<span class="string">&#x27;kde&#x27;</span>,</span><br><span class="line">                        plot_kws=&#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.6</span>&#125;,</span><br><span class="line">                        height=<span class="number">2.5</span>)</span><br><span class="line">            plt.savefig(<span class="string">&#x27;plots/features_pairplot.png&#x27;</span>)</span><br><span class="line">            plt.close()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  生成特征配对图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;特征关系图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成特征关系图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528110659212.png" alt="image-20250528110659212"></p>
<p>它直观验证了 <strong>“时长是卡路里消耗的核心驱动”</strong>，同时暴露了 <strong>“性别影响弱”</strong> 和 <strong>“异常点风险”</strong>。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528110952874.png" alt="image-20250528110952874"></p>
<p><strong>心率是卡路里消耗的核心驱动</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528111148683.png" alt="image-20250528111148683"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528111234824.png" alt="image-20250528111234824"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528111310170.png" alt="image-20250528111310170"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528111347335.png" alt="image-20250528111347335"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_categorical_analysis</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制分类特征分析图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成分类特征分析图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 性别与卡路里消耗关系</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.boxplot(x=<span class="string">&#x27;Sex&#x27;</span>, y=<span class="string">&#x27;Calories&#x27;</span>, data=data)</span><br><span class="line">        plt.title(<span class="string">&#x27;不同性别的卡路里消耗分布&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/sex_vs_calories.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建年龄分组</span></span><br><span class="line">        data_copy = data.copy()</span><br><span class="line">        data_copy[<span class="string">&#x27;Age_Group&#x27;</span>] = pd.cut(data_copy[<span class="string">&#x27;Age&#x27;</span>], bins=[<span class="number">0</span>, <span class="number">30</span>, <span class="number">45</span>, <span class="number">60</span>, <span class="number">100</span>], labels=[<span class="string">&#x27;&lt;30&#x27;</span>, <span class="string">&#x27;30-45&#x27;</span>, <span class="string">&#x27;45-60&#x27;</span>, <span class="string">&#x27;&gt;60&#x27;</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 年龄组与卡路里消耗关系</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.boxplot(x=<span class="string">&#x27;Age_Group&#x27;</span>, y=<span class="string">&#x27;Calories&#x27;</span>, data=data_copy, hue=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;不同年龄组的卡路里消耗分布&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/age_group_vs_calories.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;分类特征分析图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成分类特征分析图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528111535038.png" alt="image-20250528111535038"></p>
<p><strong>性别单独对卡路里消耗的区分度极弱</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528111609986.png" alt="image-20250528111613739"></p>
<p><strong>年龄对卡路里消耗的影响随性别变化，且高龄组存在特殊高消耗模式</strong></p>
<h2 id="四、建模和模型评价">四、建模和模型评价</h2>
<h3 id="4-1-建模策略">4.1 建模策略</h3>
<p>我们选择了以下四种回归算法进行建模：</p>
<ol>
<li>
<p><strong>决策树回归</strong>：</p>
<ul>
<li>优点：易于理解和解释，可捕捉非线性关系</li>
<li>缺点：可能过拟合，预测精度有限</li>
</ul>
</li>
<li>
<p><strong>随机森林回归</strong>：</p>
<ul>
<li>优点：集成多个决策树，降低方差，提高稳定性</li>
<li>缺点：计算开销大，模型解释性较差</li>
</ul>
</li>
<li>
<p><strong>XGBoost回归</strong>：</p>
<ul>
<li>优点：梯度提升框架，处理复杂非线性关系效果好</li>
<li>缺点：调参复杂，计算资源需求高</li>
</ul>
</li>
<li>
<p><strong>线性回归</strong>：</p>
<ul>
<li>优点：简单易懂，计算效率高</li>
<li>缺点：无法捕捉复杂的非线性关系</li>
</ul>
</li>
</ol>
<h3 id="4-2-模型训练与评估">4.2 模型训练与评估</h3>
<p>对于每个模型，我们采用以下步骤：</p>
<ol>
<li>将数据分割为训练集（80%）和验证集（20%）</li>
<li>使用训练集训练模型</li>
<li>在验证集上评估模型性能</li>
<li>比较不同模型的性能指标</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/%E5%AF%BC%E5%87%BA%E5%9B%BE%E7%89%87.png" alt="导出图片"></p>
<p>评估指标包括：</p>
<ul>
<li><strong>均方误差（MSE）</strong></li>
<li><strong>均方根误差（RMSE）</strong></li>
<li><strong>平均绝对误差（MAE）</strong></li>
<li><strong>决定系数（R²）</strong></li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515154202938.png" alt="image-20250515154202938"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515154219339.png" alt="image-20250515154219339"></p>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">卡路里消耗预测 - 数据分析课程设计</span></span><br><span class="line"><span class="string">本代码用于预测锻炼期间燃烧了多少卡路里</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score, mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time  <span class="comment"># 导入时间模块</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm  <span class="comment"># 导入tqdm用于进度显示</span></span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 设置中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>    <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子，确保结果可重现</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">use_sampling=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始卡路里消耗预测数据分析...&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. 数据获取</span></span><br><span class="line">    train_data, test_data = load_data()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 数据预处理</span></span><br><span class="line">    train_data = preprocess_data(train_data)</span><br><span class="line">    test_data = preprocess_data(test_data, is_train=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 特征工程（新增步骤）</span></span><br><span class="line">    train_data = feature_engineering(train_data)</span><br><span class="line">    test_data = feature_engineering(test_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3.1 绘制工程特征与目标变量的关系（仅使用训练集）</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在可视化工程特征与目标变量的关系...&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;plots&#x27;</span>):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;plots&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 获取工程特征列表</span></span><br><span class="line">    engineered_features = [<span class="string">&#x27;BMI&#x27;</span>, <span class="string">&#x27;Heart_Rate_Age_Ratio&#x27;</span>, <span class="string">&#x27;Exercise_Intensity&#x27;</span>, </span><br><span class="line">                          <span class="string">&#x27;Temp_Heart_Ratio&#x27;</span>, <span class="string">&#x27;Weight_Height_Ratio&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算工程特征与目标变量的相关性</span></span><br><span class="line">    feature_correlations = train_data[engineered_features + [<span class="string">&#x27;Calories&#x27;</span>]].corr()[<span class="string">&#x27;Calories&#x27;</span>].drop(<span class="string">&#x27;Calories&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制相关性条形图</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">    sns.barplot(x=feature_correlations.values, y=feature_correlations.index)</span><br><span class="line">    plt.title(<span class="string">&#x27;工程特征与卡路里消耗的相关性&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;相关系数&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;plots/engineered_features_correlation.png&#x27;</span>)</span><br><span class="line">    plt.close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 探索性数据分析</span></span><br><span class="line">    exploratory_data_analysis(train_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. 特征与目标变量分离</span></span><br><span class="line">    X_train, y_train = train_data.drop(<span class="string">&#x27;Calories&#x27;</span>, axis=<span class="number">1</span>), train_data[<span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 建模和模型评价</span></span><br><span class="line">    sample_limit = <span class="number">100000</span> <span class="keyword">if</span> use_sampling <span class="keyword">else</span> <span class="literal">None</span>  <span class="comment"># 如果使用采样，设置为10万条记录</span></span><br><span class="line">    best_model, best_score = model_training_and_evaluation(X_train, y_train, sample_limit)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 7. 使用最佳模型进行预测并生成提交文件</span></span><br><span class="line">    generate_submission(best_model, test_data)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;卡路里消耗预测数据分析完成！&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载训练集和测试集数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (训练数据, 测试数据)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在加载数据...&quot;</span>)</span><br><span class="line">        train_data = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">        test_data = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;训练集大小：<span class="subst">&#123;train_data.shape&#125;</span>, 测试集大小：<span class="subst">&#123;test_data.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> train_data, test_data</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;加载数据时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_data</span>(<span class="params">data, is_train=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对数据进行预处理</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 需要处理的数据</span></span><br><span class="line"><span class="string">        is_train (bool): 是否为训练数据</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        DataFrame: 预处理后的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行数据预处理...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建数据副本，避免修改原始数据</span></span><br><span class="line">        df = data.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示数据基本信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n数据基本信息:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(df.info())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示数据统计摘要</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n数据统计摘要:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(df.describe())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检查缺失值</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n检查缺失值:&quot;</span>)</span><br><span class="line">        missing_values = df.isnull().<span class="built_in">sum</span>()</span><br><span class="line">        <span class="built_in">print</span>(missing_values[missing_values &gt; <span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理缺失值（如果有）</span></span><br><span class="line">        <span class="keyword">if</span> df.isnull().<span class="built_in">sum</span>().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 对数值型特征使用均值填充，分类特征使用众数填充</span></span><br><span class="line">            num_features = df.select_dtypes(include=[<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]).columns</span><br><span class="line">            cat_features = df.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> num_features:</span><br><span class="line">                <span class="keyword">if</span> df[col].isnull().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">                    df[col].fillna(df[col].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> cat_features:</span><br><span class="line">                <span class="keyword">if</span> df[col].isnull().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">                    df[col].fillna(df[col].mode()[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 性别编码：将性别特征转换为数值</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Sex&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            df[<span class="string">&#x27;Sex&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 删除ID列，因为它不是预测的特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;id&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            df = df.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示处理后的数据信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n预处理后的数据信息:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(df.info())</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> df</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;数据预处理过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 探索性数据分析</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exploratory_data_analysis</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    进行探索性数据分析</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 需要分析的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行探索性数据分析...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建保存图形的文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;plots&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;plots&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 对于大数据集，可以使用采样减少计算量（可选）</span></span><br><span class="line">        sample_size = <span class="built_in">min</span>(<span class="number">10000</span>, <span class="built_in">len</span>(data))</span><br><span class="line">        data_sample = data.sample(n=sample_size, random_state=<span class="number">42</span>) <span class="keyword">if</span> <span class="built_in">len</span>(data) &gt; <span class="number">10000</span> <span class="keyword">else</span> data</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;使用<span class="subst">&#123;<span class="string">&#x27;采样数据&#x27;</span> <span class="keyword">if</span> <span class="built_in">len</span>(data) &gt; <span class="number">10000</span> <span class="keyword">else</span> <span class="string">&#x27;完整数据&#x27;</span>&#125;</span>进行可视化分析，样本大小: <span class="subst">&#123;<span class="built_in">len</span>(data_sample)&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分阶段执行可视化</span></span><br><span class="line">        plot_basic_distributions(data_sample)</span><br><span class="line">        plot_correlations(data_sample)</span><br><span class="line">        plot_feature_relationships(data_sample)</span><br><span class="line">        plot_categorical_analysis(data_sample)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;探索性数据分析完成，图表已保存到 &#x27;plots&#x27; 文件夹&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;探索性数据分析过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_basic_distributions</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制基本分布图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成基本分布图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 目标变量分布</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.histplot(data[<span class="string">&#x27;Calories&#x27;</span>], kde=<span class="literal">True</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;卡路里消耗分布&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;卡路里&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;频率&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/calories_distribution.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 特征分布图（在一个图中展示所有数值特征）</span></span><br><span class="line">        numerical_features = data.select_dtypes(include=[<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]).columns</span><br><span class="line">        numerical_features = [col <span class="keyword">for</span> col <span class="keyword">in</span> numerical_features <span class="keyword">if</span> col != <span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        fig, axes = plt.subplots(nrows=(<span class="built_in">len</span>(numerical_features)//<span class="number">3</span>) + (<span class="number">1</span> <span class="keyword">if</span> <span class="built_in">len</span>(numerical_features)%<span class="number">3</span> &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>), </span><br><span class="line">                                ncols=<span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">3</span>*((<span class="built_in">len</span>(numerical_features)//<span class="number">3</span>) + (<span class="number">1</span> <span class="keyword">if</span> <span class="built_in">len</span>(numerical_features)%<span class="number">3</span> &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>))))</span><br><span class="line">        axes = axes.flatten()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, feature <span class="keyword">in</span> <span class="built_in">enumerate</span>(numerical_features):</span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(axes):</span><br><span class="line">                sns.histplot(data[feature], kde=<span class="literal">True</span>, ax=axes[i])</span><br><span class="line">                axes[i].set_title(<span class="string">f&#x27;<span class="subst">&#123;feature&#125;</span> 分布&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 隐藏未使用的子图</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, <span class="built_in">len</span>(axes)):</span><br><span class="line">            axes[j].set_visible(<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/feature_distributions.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;基本分布图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成基本分布图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_correlations</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制相关性分析图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成相关性分析图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 相关性热力图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</span><br><span class="line">        correlation_matrix = data.corr()</span><br><span class="line">        sns.heatmap(correlation_matrix, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, fmt=<span class="string">&#x27;.2f&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;特征相关性热力图&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/correlation_heatmap.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征与目标变量的相关性条形图</span></span><br><span class="line">        correlations = data.corr()[<span class="string">&#x27;Calories&#x27;</span>].drop(<span class="string">&#x27;Calories&#x27;</span>).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">        sns.barplot(x=correlations.values, y=correlations.index)</span><br><span class="line">        plt.title(<span class="string">&#x27;特征与卡路里消耗的相关性&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;相关系数&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/feature_target_correlation.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;相关性分析图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成相关性分析图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_feature_relationships</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制特征关系图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成特征关系图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 只为相关性最高的前5个特征生成散点图</span></span><br><span class="line">        correlation_with_target = data.corr()[<span class="string">&#x27;Calories&#x27;</span>].<span class="built_in">abs</span>().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">        top_features = correlation_with_target.index[<span class="number">1</span>:<span class="number">6</span>]  <span class="comment"># 排除Calories自身</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> tqdm(top_features, desc=<span class="string">&quot;生成特征散点图&quot;</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">                sns.scatterplot(x=feature, y=<span class="string">&#x27;Calories&#x27;</span>, data=data, hue=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">                plt.title(<span class="string">f&#x27;<span class="subst">&#123;feature&#125;</span> 与卡路里消耗的关系&#x27;</span>)</span><br><span class="line">                plt.savefig(<span class="string">f&#x27;plots/<span class="subst">&#123;feature&#125;</span>_vs_calories.png&#x27;</span>)</span><br><span class="line">                plt.close()</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;  生成 <span class="subst">&#123;feature&#125;</span> 散点图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                plt.close()</span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># 继续处理下一个特征</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成一个包含所有重要特征的配对图</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;正在生成特征配对图（这可能需要一些时间）...&quot;</span>)</span><br><span class="line">            sns.pairplot(data[<span class="built_in">list</span>(top_features) + [<span class="string">&#x27;Calories&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>]], </span><br><span class="line">                        hue=<span class="string">&#x27;Sex&#x27;</span>, </span><br><span class="line">                        diag_kind=<span class="string">&#x27;kde&#x27;</span>,</span><br><span class="line">                        plot_kws=&#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.6</span>&#125;,</span><br><span class="line">                        height=<span class="number">2.5</span>)</span><br><span class="line">            plt.savefig(<span class="string">&#x27;plots/features_pairplot.png&#x27;</span>)</span><br><span class="line">            plt.close()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  生成特征配对图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;特征关系图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成特征关系图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_categorical_analysis</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制分类特征分析图</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成分类特征分析图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 性别与卡路里消耗关系</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.boxplot(x=<span class="string">&#x27;Sex&#x27;</span>, y=<span class="string">&#x27;Calories&#x27;</span>, data=data)</span><br><span class="line">        plt.title(<span class="string">&#x27;不同性别的卡路里消耗分布&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/sex_vs_calories.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建年龄分组</span></span><br><span class="line">        data_copy = data.copy()</span><br><span class="line">        data_copy[<span class="string">&#x27;Age_Group&#x27;</span>] = pd.cut(data_copy[<span class="string">&#x27;Age&#x27;</span>], bins=[<span class="number">0</span>, <span class="number">30</span>, <span class="number">45</span>, <span class="number">60</span>, <span class="number">100</span>], labels=[<span class="string">&#x27;&lt;30&#x27;</span>, <span class="string">&#x27;30-45&#x27;</span>, <span class="string">&#x27;45-60&#x27;</span>, <span class="string">&#x27;&gt;60&#x27;</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 年龄组与卡路里消耗关系</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.boxplot(x=<span class="string">&#x27;Age_Group&#x27;</span>, y=<span class="string">&#x27;Calories&#x27;</span>, data=data_copy, hue=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;不同年龄组的卡路里消耗分布&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/age_group_vs_calories.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;分类特征分析图生成完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成分类特征分析图时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        plt.close(<span class="string">&#x27;all&#x27;</span>)  <span class="comment"># 确保关闭所有图形，防止内存泄漏</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练和评估</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_training_and_evaluation</span>(<span class="params">X, y, sample_limit=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    训练多个模型并评估性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X (DataFrame): 特征数据，包括原始特征和通过特征工程创建的新特征</span></span><br><span class="line"><span class="string">        y (Series): 目标变量（卡路里消耗量）</span></span><br><span class="line"><span class="string">        sample_limit (int, optional): 可选的数据采样限制，如果指定，将随机采样数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳得分)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行模型训练和评估...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 可选的数据采样</span></span><br><span class="line">        <span class="keyword">if</span> sample_limit <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">len</span>(X) &gt; sample_limit:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;数据集较大，进行随机采样（<span class="subst">&#123;sample_limit&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(X)&#125;</span>条记录）...&quot;</span>)</span><br><span class="line">            sample_idx = np.random.choice(<span class="built_in">len</span>(X), sample_limit, replace=<span class="literal">False</span>)</span><br><span class="line">            X = X.iloc[sample_idx].copy()</span><br><span class="line">            y = y.iloc[sample_idx].copy()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;采样后数据形状: X=<span class="subst">&#123;X.shape&#125;</span>, y=<span class="subst">&#123;<span class="built_in">len</span>(y)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;使用完整数据集: X=<span class="subst">&#123;X.shape&#125;</span>, y=<span class="subst">&#123;<span class="built_in">len</span>(y)&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割数据为训练集和验证集</span></span><br><span class="line">        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征缩放</span></span><br><span class="line">        scaler = StandardScaler()</span><br><span class="line">        X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">        X_val_scaled = scaler.transform(X_val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存特征名称，用于后续的特征重要性分析</span></span><br><span class="line">        feature_names = X.columns.tolist()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义要训练的模型</span></span><br><span class="line">        models = &#123;</span><br><span class="line">            <span class="string">&quot;决策树回归&quot;</span>: DecisionTreeRegressor(random_state=<span class="number">42</span>),</span><br><span class="line">            <span class="string">&quot;随机森林回归&quot;</span>: RandomForestRegressor(</span><br><span class="line">                random_state=<span class="number">42</span>, </span><br><span class="line">                n_estimators=<span class="number">50</span>,     <span class="comment"># 减少树的数量（从100减少到50）</span></span><br><span class="line">                max_depth=<span class="number">20</span>,        <span class="comment"># 限制树的最大深度</span></span><br><span class="line">                min_samples_split=<span class="number">10</span>,<span class="comment"># 增加分裂所需的最小样本数</span></span><br><span class="line">                n_jobs=-<span class="number">1</span>,           <span class="comment"># 使用所有可用的CPU核心</span></span><br><span class="line">                verbose=<span class="number">1</span>            <span class="comment"># 显示训练进度</span></span><br><span class="line">            ),</span><br><span class="line">            <span class="string">&quot;XGBoost回归&quot;</span>: XGBRegressor(random_state=<span class="number">42</span>),</span><br><span class="line">            <span class="string">&quot;线性回归&quot;</span>: LinearRegression()</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 用于存储各模型评估结果</span></span><br><span class="line">        results = &#123;&#125;</span><br><span class="line">        best_model = <span class="literal">None</span></span><br><span class="line">        best_score = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)  <span class="comment"># 使用RMSE作为评估指标，值越小越好</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练和评估每个模型</span></span><br><span class="line">        <span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n正在训练 <span class="subst">&#123;name&#125;</span> 模型...&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 训练模型</span></span><br><span class="line">            start_time = time.time()</span><br><span class="line">            model.fit(X_train_scaled, y_train)</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            training_time = end_time - start_time</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 在验证集上进行预测</span></span><br><span class="line">            y_pred = model.predict(X_val_scaled)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算评估指标</span></span><br><span class="line">            mse = mean_squared_error(y_val, y_pred)</span><br><span class="line">            rmse = np.sqrt(mse)</span><br><span class="line">            mae = mean_absolute_error(y_val, y_pred)</span><br><span class="line">            r2 = r2_score(y_val, y_pred)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 存储结果</span></span><br><span class="line">            results[name] = &#123;</span><br><span class="line">                <span class="string">&#x27;MSE&#x27;</span>: mse,</span><br><span class="line">                <span class="string">&#x27;RMSE&#x27;</span>: rmse,</span><br><span class="line">                <span class="string">&#x27;MAE&#x27;</span>: mae,</span><br><span class="line">                <span class="string">&#x27;R²&#x27;</span>: r2,</span><br><span class="line">                <span class="string">&#x27;model&#x27;</span>: model,</span><br><span class="line">                <span class="string">&#x27;training_time&#x27;</span>: training_time</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 输出评估结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span> 评估结果:&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  均方误差 (MSE): <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  均方根误差 (RMSE): <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  平均绝对误差 (MAE): <span class="subst">&#123;mae:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  R² 分数: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  训练时间: <span class="subst">&#123;training_time:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新最佳模型</span></span><br><span class="line">            <span class="keyword">if</span> rmse &lt; best_score:</span><br><span class="line">                best_score = rmse</span><br><span class="line">                best_model = model</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 比较模型性能并可视化</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n模型性能比较:&quot;</span>)</span><br><span class="line">        metrics = [<span class="string">&#x27;MSE&#x27;</span>, <span class="string">&#x27;RMSE&#x27;</span>, <span class="string">&#x27;MAE&#x27;</span>, <span class="string">&#x27;R²&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> metric <span class="keyword">in</span> metrics:</span><br><span class="line">            plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">            model_names = <span class="built_in">list</span>(results.keys())</span><br><span class="line">            <span class="keyword">if</span> metric == <span class="string">&#x27;R²&#x27;</span>:</span><br><span class="line">                <span class="comment"># R²越高越好</span></span><br><span class="line">                metric_values = [results[name][metric] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">                colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> val == <span class="built_in">max</span>([results[name][metric] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]) <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> val <span class="keyword">in</span> metric_values]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 其他指标越低越好</span></span><br><span class="line">                metric_values = [results[name][metric] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">                colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> val == <span class="built_in">min</span>([results[name][metric] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]) <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> val <span class="keyword">in</span> metric_values]</span><br><span class="line">            </span><br><span class="line">            plt.bar(model_names, metric_values, color=colors)</span><br><span class="line">            plt.title(<span class="string">f&#x27;不同模型的<span class="subst">&#123;metric&#125;</span>比较&#x27;</span>)</span><br><span class="line">            plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">            plt.ylabel(metric)</span><br><span class="line">            plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">            plt.tight_layout()</span><br><span class="line">            plt.savefig(<span class="string">f&#x27;plots/model_comparison_<span class="subst">&#123;metric&#125;</span>.png&#x27;</span>)</span><br><span class="line">            plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 可视化模型训练时间</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        model_names = <span class="built_in">list</span>(results.keys())</span><br><span class="line">        training_times = [results[name][<span class="string">&#x27;training_time&#x27;</span>] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">        colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> t == <span class="built_in">min</span>(training_times) <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> t <span class="keyword">in</span> training_times]</span><br><span class="line">        </span><br><span class="line">        plt.bar(model_names, training_times, color=colors)</span><br><span class="line">        plt.title(<span class="string">&#x27;不同模型的训练时间比较&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;训练时间 (秒)&#x27;</span>)</span><br><span class="line">        plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/model_comparison_training_time.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 时间-性能权衡分析（RMSE/时间）</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        model_names = <span class="built_in">list</span>(results.keys())</span><br><span class="line">        rmse_values = [results[name][<span class="string">&#x27;RMSE&#x27;</span>] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">        efficiency = [rmse / time <span class="keyword">for</span> rmse, time <span class="keyword">in</span> <span class="built_in">zip</span>(rmse_values, training_times)]</span><br><span class="line">        colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> e == <span class="built_in">min</span>(efficiency) <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> e <span class="keyword">in</span> efficiency]</span><br><span class="line">        </span><br><span class="line">        plt.bar(model_names, efficiency, color=colors)</span><br><span class="line">        plt.title(<span class="string">&#x27;模型效率分析 (RMSE/训练时间)&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;效率指标 (越低越好)&#x27;</span>)</span><br><span class="line">        plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/model_comparison_efficiency.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分析特征重要性（仅对支持特征重要性的模型）</span></span><br><span class="line">        best_model_name = [name <span class="keyword">for</span> name, res <span class="keyword">in</span> results.items() <span class="keyword">if</span> res[<span class="string">&#x27;model&#x27;</span>] == best_model][<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n最佳模型是: <span class="subst">&#123;best_model_name&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;最佳RMSE: <span class="subst">&#123;best_score:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分析最佳模型的特征重要性</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(best_model, <span class="string">&#x27;feature_importances_&#x27;</span>):</span><br><span class="line">            plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">            importances = best_model.feature_importances_</span><br><span class="line">            indices = np.argsort(importances)[::-<span class="number">1</span>]</span><br><span class="line">            </span><br><span class="line">            plt.title(<span class="string">f&#x27;<span class="subst">&#123;best_model_name&#125;</span>模型的特征重要性&#x27;</span>)</span><br><span class="line">            plt.bar(<span class="built_in">range</span>(X.shape[<span class="number">1</span>]), importances[indices], align=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">            plt.xticks(<span class="built_in">range</span>(X.shape[<span class="number">1</span>]), [feature_names[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices], rotation=<span class="number">90</span>)</span><br><span class="line">            plt.tight_layout()</span><br><span class="line">            plt.savefig(<span class="string">&#x27;plots/best_model_feature_importance.png&#x27;</span>)</span><br><span class="line">            plt.close()</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\n特征重要性排序:&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> i, idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(indices):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>. <span class="subst">&#123;feature_names[idx]&#125;</span>: <span class="subst">&#123;importances[idx]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存最佳模型</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;models&#x27;</span>):</span><br><span class="line">                os.makedirs(<span class="string">&#x27;models&#x27;</span>)</span><br><span class="line">            joblib.dump(best_model, <span class="string">&#x27;models/best_model.pkl&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\n最佳模型已保存到: models/best_model.pkl&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;保存模型时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_model, best_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;模型训练和评估过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成提交文件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_submission</span>(<span class="params">model, test_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用训练好的模型生成提交文件</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model: 训练好的模型</span></span><br><span class="line"><span class="string">        test_data (DataFrame): 测试数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成提交文件...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存测试集的ID</span></span><br><span class="line">        test_ids = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征缩放</span></span><br><span class="line">        scaler = StandardScaler()</span><br><span class="line">        X_test_scaled = scaler.fit_transform(test_data)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 预测</span></span><br><span class="line">        predictions = model.predict(X_test_scaled)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 确保预测值为非负数（卡路里不可能为负）</span></span><br><span class="line">        predictions = np.maximum(predictions, <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建提交文件</span></span><br><span class="line">        submission = pd.DataFrame(&#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: test_ids,</span><br><span class="line">            <span class="string">&#x27;Calories&#x27;</span>: predictions</span><br><span class="line">        &#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存为CSV文件</span></span><br><span class="line">        submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;提交文件已生成: submission.csv，包含 <span class="subst">&#123;<span class="built_in">len</span>(submission)&#125;</span> 个预测结果&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示预测值的基本统计信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n预测结果统计信息:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;最小值: <span class="subst">&#123;predictions.<span class="built_in">min</span>():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;最大值: <span class="subst">&#123;predictions.<span class="built_in">max</span>():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;平均值: <span class="subst">&#123;predictions.mean():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;中位数: <span class="subst">&#123;np.median(predictions):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;标准差: <span class="subst">&#123;predictions.std():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成提交文件过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征工程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_engineering</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建新特征以提高模型性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 预处理后的数据</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        DataFrame: 包含新特征的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行特征工程...&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程前数据形状: <span class="subst">&#123;data.shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建数据副本</span></span><br><span class="line">        df = data.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录原始特征列表</span></span><br><span class="line">        original_features = df.columns.tolist()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 创建BMI特征（体重指数）</span></span><br><span class="line">        df[<span class="string">&#x27;BMI&#x27;</span>] = df[<span class="string">&#x27;Weight&#x27;</span>] / ((df[<span class="string">&#x27;Height&#x27;</span>]/<span class="number">100</span>) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 创建心率与年龄的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Heart_Rate_Age_Ratio&#x27;</span>] = df[<span class="string">&#x27;Heart_Rate&#x27;</span>] / df[<span class="string">&#x27;Age&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 创建锻炼强度指标</span></span><br><span class="line">        df[<span class="string">&#x27;Exercise_Intensity&#x27;</span>] = df[<span class="string">&#x27;Heart_Rate&#x27;</span>] * df[<span class="string">&#x27;Duration&#x27;</span>] / <span class="number">100</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 创建体温与心率的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Temp_Heart_Ratio&#x27;</span>] = df[<span class="string">&#x27;Body_Temp&#x27;</span>] / df[<span class="string">&#x27;Heart_Rate&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 体重与身高的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Weight_Height_Ratio&#x27;</span>] = df[<span class="string">&#x27;Weight&#x27;</span>] / (df[<span class="string">&#x27;Height&#x27;</span>]/<span class="number">100</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取新创建的特征列表</span></span><br><span class="line">        new_features = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> original_features]</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程完成，创建了 <span class="subst">&#123;<span class="built_in">len</span>(new_features)&#125;</span> 个新特征:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> new_features:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  - <span class="subst">&#123;feature&#125;</span>: 均值=<span class="subst">&#123;df[feature].mean():<span class="number">.4</span>f&#125;</span>, 标准差=<span class="subst">&#123;df[feature].std():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程后数据形状: <span class="subst">&#123;df.shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> df</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 是否使用数据采样来加速训练（开发阶段设为True，最终模型训练设为False）</span></span><br><span class="line">    USE_SAMPLING = <span class="literal">False</span></span><br><span class="line">    main(use_sampling=USE_SAMPLING) </span><br></pre></td></tr></table></figure>
<h2 id="五、模型优化">五、模型优化</h2>
<h3 id="5-1-超参数调优">5.1 超参数调优</h3>
<p>针对不同算法，我们使用网格搜索或随机搜索进行超参数调优：</p>
<ol>
<li>
<p><strong>决策树优化</strong>：</p>
<ul>
<li>参数：max_depth, min_samples_split, min_samples_leaf, max_features</li>
<li>使用GridSearchCV进行网格搜索</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_decision_tree</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化决策树回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳参数, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化决策树回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 参数网格 - 适度减少参数空间但保留关键选项</span></span><br><span class="line">        param_grid = &#123;</span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: [<span class="literal">None</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>],  <span class="comment"># 恢复None选项，对大数据集可能有益</span></span><br><span class="line">            <span class="string">&#x27;min_samples_split&#x27;</span>: [<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>],</span><br><span class="line">            <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">            <span class="string">&#x27;max_features&#x27;</span>: [<span class="string">&#x27;auto&#x27;</span>, <span class="string">&#x27;sqrt&#x27;</span>, <span class="string">&#x27;log2&#x27;</span>]  <span class="comment"># 保留所有特征选择方法</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 基础模型</span></span><br><span class="line">        dt = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对于决策树，恢复使用GridSearchCV以确保找到最优参数</span></span><br><span class="line">        <span class="comment"># 决策树训练速度相对较快，即使数据量大也可接受网格搜索</span></span><br><span class="line">        grid_search = GridSearchCV(</span><br><span class="line">            estimator=dt,</span><br><span class="line">            param_grid=param_grid,</span><br><span class="line">            cv=<span class="number">3</span>,  <span class="comment"># 保持减少的交叉验证折数以节省时间</span></span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,</span><br><span class="line">            n_jobs=-<span class="number">1</span>,</span><br><span class="line">            verbose=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        grid_search.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;决策树网格搜索耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = grid_search.best_params_</span><br><span class="line">        best_dt = grid_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = best_dt.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;决策树最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制特征重要性</span></span><br><span class="line">        feature_importances = best_dt.feature_importances_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=feature_importances, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;决策树 - 特征重要性&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/dt_feature_importance.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(best_dt, <span class="string">&#x27;models/decision_tree_best.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_dt, best_params, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化决策树模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>随机森林优化</strong>：</p>
<ul>
<li>参数：n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features</li>
<li>使用RandomizedSearchCV进行随机搜索</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_random_forest</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化随机森林回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳参数, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化随机森林回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 由于随机森林计算开销大，即使数据量大也使用随机搜索而非网格搜索</span></span><br><span class="line">        param_distributions = &#123;</span><br><span class="line">            <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">150</span>, <span class="number">200</span>],  <span class="comment"># 恢复200作为选项</span></span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: [<span class="literal">None</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>],  <span class="comment"># 恢复None和30选项，对大数据集可能有益</span></span><br><span class="line">            <span class="string">&#x27;min_samples_split&#x27;</span>: [<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>],  <span class="comment"># 恢复10作为选项</span></span><br><span class="line">            <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>],  <span class="comment"># 恢复4作为选项</span></span><br><span class="line">            <span class="string">&#x27;max_features&#x27;</span>: [<span class="string">&#x27;auto&#x27;</span>, <span class="string">&#x27;sqrt&#x27;</span>, <span class="string">&#x27;log2&#x27;</span>],  <span class="comment"># 恢复log2作为选项</span></span><br><span class="line">            <span class="string">&#x27;bootstrap&#x27;</span>: [<span class="literal">True</span>],  <span class="comment"># 使用bootstrap抽样</span></span><br><span class="line">            <span class="string">&#x27;max_samples&#x27;</span>: [<span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]  <span class="comment"># 控制每棵树使用的样本比例</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 基础模型 - 添加n_jobs参数使用多核CPU</span></span><br><span class="line">        rf = RandomForestRegressor(random_state=<span class="number">42</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机搜索 - 增加n_iter以提高搜索质量</span></span><br><span class="line">        random_search = RandomizedSearchCV(</span><br><span class="line">            estimator=rf,</span><br><span class="line">            param_distributions=param_distributions,</span><br><span class="line">            n_iter=<span class="number">20</span>,  <span class="comment"># 恢复原始的20次尝试以提高搜索质量</span></span><br><span class="line">            cv=<span class="number">3</span>,  <span class="comment"># 保持减少的交叉验证折数以节省时间</span></span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,</span><br><span class="line">            n_jobs=-<span class="number">1</span>,</span><br><span class="line">            verbose=<span class="number">1</span>,</span><br><span class="line">            random_state=<span class="number">42</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        random_search.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;随机森林随机搜索耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = random_search.best_params_</span><br><span class="line">        best_rf = random_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = best_rf.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;随机森林最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制特征重要性</span></span><br><span class="line">        feature_importances = best_rf.feature_importances_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=feature_importances, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;随机森林 - 特征重要性&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/rf_feature_importance.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(best_rf, <span class="string">&#x27;models/random_forest_best.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_rf, best_params, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化随机森林模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>XGBoost优化</strong>：</p>
<ul>
<li>参数：n_estimators, max_depth, learning_rate, subsample, colsample_bytree, gamma</li>
<li>使用RandomizedSearchCV进行随机搜索</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_xgboost</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化XGBoost回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳参数, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化XGBoost回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 参数网格</span></span><br><span class="line">        param_grid = &#123;</span><br><span class="line">            <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>],</span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>],</span><br><span class="line">            <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],</span><br><span class="line">            <span class="string">&#x27;subsample&#x27;</span>: [<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>],</span><br><span class="line">            <span class="string">&#x27;colsample_bytree&#x27;</span>: [<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>],</span><br><span class="line">            <span class="string">&#x27;gamma&#x27;</span>: [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.2</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 基础模型 - 添加n_jobs参数使用多核CPU和更快的tree_method</span></span><br><span class="line">        xgb_model = xgb.XGBRegressor(random_state=<span class="number">42</span>, n_jobs=-<span class="number">1</span>, tree_method=<span class="string">&#x27;hist&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机搜索</span></span><br><span class="line">        random_search = RandomizedSearchCV(</span><br><span class="line">            estimator=xgb_model,</span><br><span class="line">            param_distributions=param_grid,</span><br><span class="line">            n_iter=<span class="number">20</span>,  <span class="comment"># 尝试20种组合</span></span><br><span class="line">            cv=<span class="number">5</span>,</span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,</span><br><span class="line">            n_jobs=-<span class="number">1</span>,</span><br><span class="line">            verbose=<span class="number">1</span>,</span><br><span class="line">            random_state=<span class="number">42</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        random_search.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;XGBoost随机搜索耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = random_search.best_params_</span><br><span class="line">        best_xgb = random_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = best_xgb.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;XGBoost最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制特征重要性</span></span><br><span class="line">        feature_importances = best_xgb.feature_importances_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=feature_importances, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;XGBoost - 特征重要性&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/xgb_feature_importance.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(best_xgb, <span class="string">&#x27;models/xgboost_best.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_xgb, best_params, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化XGBoost模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>线性回归</strong>：</p>
<ul>
<li>线性回归没有需要调优的超参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_linear_regression</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化线性回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (训练好的模型, None, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化线性回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 线性回归没有超参数需要调优，直接训练模型</span></span><br><span class="line">        lr = LinearRegression()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        lr.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;线性回归训练耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = lr.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制系数</span></span><br><span class="line">        coefficients = lr.coef_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=coefficients, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;线性回归 - 特征系数&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/lr_coefficients.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(lr, <span class="string">&#x27;models/linear_regression.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> lr, <span class="literal">None</span>, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化线性回归模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="5-2-特征重要性分析">5.2 特征重要性分析</h3>
<p>通过分析各模型的特征重要性，我们发现：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515152921306.png" alt="image-20250515152921306"></p>
<h3 id="5-3-优化后的模型比较">5.3 优化后的模型比较</h3>
<p>我们对比了所有优化后的模型性能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compare_optimized_models</span>(<span class="params">results</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    比较优化后的模型性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        results (dict): 包含各模型结果的字典</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        str: 基于RMSLE的最佳模型名称</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;比较优化后的模型性能...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 提取模型名称和评估指标</span></span><br><span class="line">        model_names = <span class="built_in">list</span>(results.keys())</span><br><span class="line">        rmse_values = [results[name][<span class="string">&#x27;rmse&#x27;</span>] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">        rmsle_values = [results[name][<span class="string">&#x27;rmsle&#x27;</span>] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 找出基于RMSE的最佳模型</span></span><br><span class="line">        best_rmse_idx = np.argmin(rmse_values)</span><br><span class="line">        rmse_colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> i == best_rmse_idx <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(model_names))]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 找出基于RMSLE的最佳模型（竞赛评估指标）</span></span><br><span class="line">        best_rmsle_idx = np.argmin(rmsle_values)</span><br><span class="line">        rmsle_colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> i == best_rmsle_idx <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(model_names))]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制RMSE比较图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        plt.bar(model_names, rmse_values, color=rmse_colors)</span><br><span class="line">        plt.title(<span class="string">&#x27;优化后的模型性能比较 (RMSE)&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSE (越低越好)&#x27;</span>)</span><br><span class="line">        plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/optimized_models_comparison_rmse.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制RMSLE比较图（竞赛评估指标）</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        plt.bar(model_names, rmsle_values, color=rmsle_colors)</span><br><span class="line">        plt.title(<span class="string">&#x27;优化后的模型性能比较 (RMSLE) - 竞赛评估指标&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSLE (越低越好)&#x27;</span>)</span><br><span class="line">        plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/optimized_models_comparison_rmsle.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出比较结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n模型性能比较 (RMSE):&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(model_names):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: <span class="subst">&#123;rmse_values[i]:<span class="number">.4</span>f&#125;</span>&quot;</span> + (<span class="string">&quot; (最佳)&quot;</span> <span class="keyword">if</span> i == best_rmse_idx <span class="keyword">else</span> <span class="string">&quot;&quot;</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n模型性能比较 (RMSLE) - 竞赛评估指标:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(model_names):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: <span class="subst">&#123;rmsle_values[i]:<span class="number">.4</span>f&#125;</span>&quot;</span> + (<span class="string">&quot; (最佳)&quot;</span> <span class="keyword">if</span> i == best_rmsle_idx <span class="keyword">else</span> <span class="string">&quot;&quot;</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果RMSE和RMSLE选出的最佳模型不同，输出说明</span></span><br><span class="line">        <span class="keyword">if</span> best_rmse_idx != best_rmsle_idx:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n注意: 基于RMSE的最佳模型是 <span class="subst">&#123;model_names[best_rmse_idx]&#125;</span>，而基于RMSLE的最佳模型是 <span class="subst">&#123;model_names[best_rmsle_idx]&#125;</span>。&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;由于竞赛使用RMSLE作为评估指标，我们将选择基于RMSLE的最佳模型。&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 返回基于RMSLE的最佳模型名称</span></span><br><span class="line">        <span class="keyword">return</span> model_names[best_rmsle_idx]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;比较优化后的模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515153858400.png" alt="image-20250515153858400"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515153916182.png" alt="image-20250515153916182"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515153934775.png" alt="image-20250515153934775"></p>
<p>优化的完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">卡路里消耗预测 - 模型优化</span></span><br><span class="line"><span class="string">本代码用于优化预测模型的超参数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score, mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 设置中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>    <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子，确保结果可重现</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rmsle</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算Root Mean Squared Logarithmic Error (RMSLE)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true: 真实值</span></span><br><span class="line"><span class="string">        y_pred: 预测值</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        float: RMSLE值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 确保输入值为正数（避免对负数取对数）</span></span><br><span class="line">    y_true = np.maximum(y_true, <span class="number">0</span>)</span><br><span class="line">    y_pred = np.maximum(y_pred, <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算RMSLE</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_preprocessed_data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载预处理后的训练数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (X_train, X_val, y_train, y_val) - 训练特征、验证特征、训练目标、验证目标</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 加载训练数据</span></span><br><span class="line">        train_data = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 数据预处理</span></span><br><span class="line">        <span class="comment"># 删除id列</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;id&#x27;</span> <span class="keyword">in</span> train_data.columns:</span><br><span class="line">            train_data.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 性别编码</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Sex&#x27;</span> <span class="keyword">in</span> train_data.columns:</span><br><span class="line">            train_data[<span class="string">&#x27;Sex&#x27;</span>] = train_data[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分离特征和目标变量</span></span><br><span class="line">        X = train_data.drop(<span class="string">&#x27;Calories&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">        y = train_data[<span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割数据为训练集和验证集</span></span><br><span class="line">        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征缩放</span></span><br><span class="line">        scaler = StandardScaler()</span><br><span class="line">        X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">        X_val_scaled = scaler.transform(X_val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存scaler，用于后续预测</span></span><br><span class="line">        joblib.dump(scaler, <span class="string">&#x27;scaler.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> X_train_scaled, X_val_scaled, y_train, y_val</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;加载和预处理数据时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_decision_tree</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化决策树回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳参数, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化决策树回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 参数网格 - 适度减少参数空间但保留关键选项</span></span><br><span class="line">        param_grid = &#123;</span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: [<span class="literal">None</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>],  <span class="comment"># 恢复None选项，对大数据集可能有益</span></span><br><span class="line">            <span class="string">&#x27;min_samples_split&#x27;</span>: [<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>],</span><br><span class="line">            <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">            <span class="string">&#x27;max_features&#x27;</span>: [<span class="string">&#x27;auto&#x27;</span>, <span class="string">&#x27;sqrt&#x27;</span>, <span class="string">&#x27;log2&#x27;</span>]  <span class="comment"># 保留所有特征选择方法</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 基础模型</span></span><br><span class="line">        dt = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对于决策树，恢复使用GridSearchCV以确保找到最优参数</span></span><br><span class="line">        <span class="comment"># 决策树训练速度相对较快，即使数据量大也可接受网格搜索</span></span><br><span class="line">        grid_search = GridSearchCV(</span><br><span class="line">            estimator=dt,</span><br><span class="line">            param_grid=param_grid,</span><br><span class="line">            cv=<span class="number">3</span>,  <span class="comment"># 保持减少的交叉验证折数以节省时间</span></span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,</span><br><span class="line">            n_jobs=-<span class="number">1</span>,</span><br><span class="line">            verbose=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        grid_search.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;决策树网格搜索耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = grid_search.best_params_</span><br><span class="line">        best_dt = grid_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = best_dt.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;决策树最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制特征重要性</span></span><br><span class="line">        feature_importances = best_dt.feature_importances_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=feature_importances, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;决策树 - 特征重要性&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/dt_feature_importance.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(best_dt, <span class="string">&#x27;models/decision_tree_best.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_dt, best_params, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化决策树模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_random_forest</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化随机森林回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳参数, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化随机森林回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 由于随机森林计算开销大，即使数据量大也使用随机搜索而非网格搜索</span></span><br><span class="line">        param_distributions = &#123;</span><br><span class="line">            <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">150</span>, <span class="number">200</span>],  <span class="comment"># 恢复200作为选项</span></span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: [<span class="literal">None</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>],  <span class="comment"># 恢复None和30选项，对大数据集可能有益</span></span><br><span class="line">            <span class="string">&#x27;min_samples_split&#x27;</span>: [<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>],  <span class="comment"># 恢复10作为选项</span></span><br><span class="line">            <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>],  <span class="comment"># 恢复4作为选项</span></span><br><span class="line">            <span class="string">&#x27;max_features&#x27;</span>: [<span class="string">&#x27;auto&#x27;</span>, <span class="string">&#x27;sqrt&#x27;</span>, <span class="string">&#x27;log2&#x27;</span>],  <span class="comment"># 恢复log2作为选项</span></span><br><span class="line">            <span class="string">&#x27;bootstrap&#x27;</span>: [<span class="literal">True</span>],  <span class="comment"># 使用bootstrap抽样</span></span><br><span class="line">            <span class="string">&#x27;max_samples&#x27;</span>: [<span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]  <span class="comment"># 控制每棵树使用的样本比例</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 基础模型 - 添加n_jobs参数使用多核CPU</span></span><br><span class="line">        rf = RandomForestRegressor(random_state=<span class="number">42</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机搜索 - 增加n_iter以提高搜索质量</span></span><br><span class="line">        random_search = RandomizedSearchCV(</span><br><span class="line">            estimator=rf,</span><br><span class="line">            param_distributions=param_distributions,</span><br><span class="line">            n_iter=<span class="number">20</span>,  <span class="comment"># 恢复原始的20次尝试以提高搜索质量</span></span><br><span class="line">            cv=<span class="number">3</span>,  <span class="comment"># 保持减少的交叉验证折数以节省时间</span></span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,</span><br><span class="line">            n_jobs=-<span class="number">1</span>,</span><br><span class="line">            verbose=<span class="number">1</span>,</span><br><span class="line">            random_state=<span class="number">42</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        random_search.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;随机森林随机搜索耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = random_search.best_params_</span><br><span class="line">        best_rf = random_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = best_rf.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;随机森林最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制特征重要性</span></span><br><span class="line">        feature_importances = best_rf.feature_importances_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=feature_importances, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;随机森林 - 特征重要性&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/rf_feature_importance.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(best_rf, <span class="string">&#x27;models/random_forest_best.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_rf, best_params, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化随机森林模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_xgboost</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化XGBoost回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳参数, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化XGBoost回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 参数网格</span></span><br><span class="line">        param_grid = &#123;</span><br><span class="line">            <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>],</span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>],</span><br><span class="line">            <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],</span><br><span class="line">            <span class="string">&#x27;subsample&#x27;</span>: [<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>],</span><br><span class="line">            <span class="string">&#x27;colsample_bytree&#x27;</span>: [<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>],</span><br><span class="line">            <span class="string">&#x27;gamma&#x27;</span>: [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.2</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 基础模型 - 添加n_jobs参数使用多核CPU和更快的tree_method</span></span><br><span class="line">        xgb_model = xgb.XGBRegressor(random_state=<span class="number">42</span>, n_jobs=-<span class="number">1</span>, tree_method=<span class="string">&#x27;hist&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机搜索</span></span><br><span class="line">        random_search = RandomizedSearchCV(</span><br><span class="line">            estimator=xgb_model,</span><br><span class="line">            param_distributions=param_grid,</span><br><span class="line">            n_iter=<span class="number">20</span>,  <span class="comment"># 尝试20种组合</span></span><br><span class="line">            cv=<span class="number">5</span>,</span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,</span><br><span class="line">            n_jobs=-<span class="number">1</span>,</span><br><span class="line">            verbose=<span class="number">1</span>,</span><br><span class="line">            random_state=<span class="number">42</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        random_search.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;XGBoost随机搜索耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = random_search.best_params_</span><br><span class="line">        best_xgb = random_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = best_xgb.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;XGBoost最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制特征重要性</span></span><br><span class="line">        feature_importances = best_xgb.feature_importances_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=feature_importances, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;XGBoost - 特征重要性&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/xgb_feature_importance.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(best_xgb, <span class="string">&#x27;models/xgboost_best.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_xgb, best_params, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化XGBoost模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_linear_regression</span>(<span class="params">X_train, X_val, y_train, y_val</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化线性回归模型</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X_train, X_val, y_train, y_val: 训练和验证数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (训练好的模型, None, 验证集RMSE, 验证集RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始优化线性回归模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 线性回归没有超参数需要调优，直接训练模型</span></span><br><span class="line">        lr = LinearRegression()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始计时</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        lr.fit(X_train, y_train)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束计时</span></span><br><span class="line">        end_time = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;线性回归训练耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        y_pred = lr.predict(X_val)</span><br><span class="line">        rmse = np.sqrt(mean_squared_error(y_val, y_pred))</span><br><span class="line">        r2 = r2_score(y_val, y_pred)</span><br><span class="line">        rmsle_score = rmsle(y_val, y_pred)  <span class="comment"># 计算RMSLE</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSE: <span class="subst">&#123;rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集R²: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;验证集RMSLE: <span class="subst">&#123;rmsle_score:<span class="number">.4</span>f&#125;</span> (竞赛评估指标)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制系数</span></span><br><span class="line">        coefficients = lr.coef_</span><br><span class="line">        features = [<span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Duration&#x27;</span>, <span class="string">&#x27;Heart_Rate&#x27;</span>, <span class="string">&#x27;Body_Temp&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.barplot(x=coefficients, y=features)</span><br><span class="line">        plt.title(<span class="string">&#x27;线性回归 - 特征系数&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/lr_coefficients.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        joblib.dump(lr, <span class="string">&#x27;models/linear_regression.joblib&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> lr, <span class="literal">None</span>, rmse, rmsle_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;优化线性回归模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare_optimized_models</span>(<span class="params">results</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    比较优化后的模型性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        results (dict): 包含各模型结果的字典</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        str: 基于RMSLE的最佳模型名称</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;比较优化后的模型性能...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 提取模型名称和评估指标</span></span><br><span class="line">        model_names = <span class="built_in">list</span>(results.keys())</span><br><span class="line">        rmse_values = [results[name][<span class="string">&#x27;rmse&#x27;</span>] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">        rmsle_values = [results[name][<span class="string">&#x27;rmsle&#x27;</span>] <span class="keyword">for</span> name <span class="keyword">in</span> model_names]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 找出基于RMSE的最佳模型</span></span><br><span class="line">        best_rmse_idx = np.argmin(rmse_values)</span><br><span class="line">        rmse_colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> i == best_rmse_idx <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(model_names))]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 找出基于RMSLE的最佳模型（竞赛评估指标）</span></span><br><span class="line">        best_rmsle_idx = np.argmin(rmsle_values)</span><br><span class="line">        rmsle_colors = [<span class="string">&#x27;green&#x27;</span> <span class="keyword">if</span> i == best_rmsle_idx <span class="keyword">else</span> <span class="string">&#x27;blue&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(model_names))]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制RMSE比较图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        plt.bar(model_names, rmse_values, color=rmse_colors)</span><br><span class="line">        plt.title(<span class="string">&#x27;优化后的模型性能比较 (RMSE)&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSE (越低越好)&#x27;</span>)</span><br><span class="line">        plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/optimized_models_comparison_rmse.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制RMSLE比较图（竞赛评估指标）</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        plt.bar(model_names, rmsle_values, color=rmsle_colors)</span><br><span class="line">        plt.title(<span class="string">&#x27;优化后的模型性能比较 (RMSLE) - 竞赛评估指标&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSLE (越低越好)&#x27;</span>)</span><br><span class="line">        plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.savefig(<span class="string">&#x27;plots/optimized_models_comparison_rmsle.png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出比较结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n模型性能比较 (RMSE):&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(model_names):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: <span class="subst">&#123;rmse_values[i]:<span class="number">.4</span>f&#125;</span>&quot;</span> + (<span class="string">&quot; (最佳)&quot;</span> <span class="keyword">if</span> i == best_rmse_idx <span class="keyword">else</span> <span class="string">&quot;&quot;</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n模型性能比较 (RMSLE) - 竞赛评估指标:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(model_names):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: <span class="subst">&#123;rmsle_values[i]:<span class="number">.4</span>f&#125;</span>&quot;</span> + (<span class="string">&quot; (最佳)&quot;</span> <span class="keyword">if</span> i == best_rmsle_idx <span class="keyword">else</span> <span class="string">&quot;&quot;</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果RMSE和RMSLE选出的最佳模型不同，输出说明</span></span><br><span class="line">        <span class="keyword">if</span> best_rmse_idx != best_rmsle_idx:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n注意: 基于RMSE的最佳模型是 <span class="subst">&#123;model_names[best_rmse_idx]&#125;</span>，而基于RMSLE的最佳模型是 <span class="subst">&#123;model_names[best_rmsle_idx]&#125;</span>。&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;由于竞赛使用RMSLE作为评估指标，我们将选择基于RMSLE的最佳模型。&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 返回基于RMSLE的最佳模型名称</span></span><br><span class="line">        <span class="keyword">return</span> model_names[best_rmsle_idx]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;比较优化后的模型时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_submission_with_best_model</span>(<span class="params">best_model_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用最佳模型生成提交文件</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        best_model_name (str): 最佳模型的名称</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;使用最佳模型 <span class="subst">&#123;best_model_name&#125;</span> 生成提交文件...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载最佳模型</span></span><br><span class="line">        model_file = <span class="string">f&#x27;models/<span class="subst">&#123;best_model_name&#125;</span>.joblib&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(model_file):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;错误：找不到模型文件 <span class="subst">&#123;model_file&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        best_model = joblib.load(model_file)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载测试数据</span></span><br><span class="line">        test_data = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line">        test_ids = test_data[<span class="string">&#x27;id&#x27;</span>].copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 预处理测试数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;id&#x27;</span> <span class="keyword">in</span> test_data.columns:</span><br><span class="line">            test_data.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Sex&#x27;</span> <span class="keyword">in</span> test_data.columns:</span><br><span class="line">            test_data[<span class="string">&#x27;Sex&#x27;</span>] = test_data[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载scaler</span></span><br><span class="line">        scaler = joblib.load(<span class="string">&#x27;scaler.joblib&#x27;</span>)</span><br><span class="line">        X_test_scaled = scaler.transform(test_data)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 预测</span></span><br><span class="line">        predictions = best_model.predict(X_test_scaled)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建提交文件</span></span><br><span class="line">        submission = pd.DataFrame(&#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: test_ids,</span><br><span class="line">            <span class="string">&#x27;Calories&#x27;</span>: predictions</span><br><span class="line">        &#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存为CSV文件</span></span><br><span class="line">        submission_file = <span class="string">f&#x27;submission_<span class="subst">&#123;best_model_name&#125;</span>.csv&#x27;</span></span><br><span class="line">        submission.to_csv(submission_file, index=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;提交文件已生成: <span class="subst">&#123;submission_file&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成提交文件过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    主函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始模型优化流程...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建保存模型和图形的文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;models&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;models&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;plots&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;plots&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载预处理后的数据</span></span><br><span class="line">        X_train, X_val, y_train, y_val = load_preprocessed_data()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 优化各模型并存储结果</span></span><br><span class="line">        results = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 决策树</span></span><br><span class="line">        dt_model, dt_params, dt_rmse, dt_rmsle = optimize_decision_tree(X_train, X_val, y_train, y_val)</span><br><span class="line">        results[<span class="string">&#x27;decision_tree_best&#x27;</span>] = &#123;<span class="string">&#x27;model&#x27;</span>: dt_model, <span class="string">&#x27;params&#x27;</span>: dt_params, <span class="string">&#x27;rmse&#x27;</span>: dt_rmse, <span class="string">&#x27;rmsle&#x27;</span>: dt_rmsle&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机森林</span></span><br><span class="line">        rf_model, rf_params, rf_rmse, rf_rmsle = optimize_random_forest(X_train, X_val, y_train, y_val)</span><br><span class="line">        results[<span class="string">&#x27;random_forest_best&#x27;</span>] = &#123;<span class="string">&#x27;model&#x27;</span>: rf_model, <span class="string">&#x27;params&#x27;</span>: rf_params, <span class="string">&#x27;rmse&#x27;</span>: rf_rmse, <span class="string">&#x27;rmsle&#x27;</span>: rf_rmsle&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># XGBoost</span></span><br><span class="line">        xgb_model, xgb_params, xgb_rmse, xgb_rmsle = optimize_xgboost(X_train, X_val, y_train, y_val)</span><br><span class="line">        results[<span class="string">&#x27;xgboost_best&#x27;</span>] = &#123;<span class="string">&#x27;model&#x27;</span>: xgb_model, <span class="string">&#x27;params&#x27;</span>: xgb_params, <span class="string">&#x27;rmse&#x27;</span>: xgb_rmse, <span class="string">&#x27;rmsle&#x27;</span>: xgb_rmsle&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 线性回归</span></span><br><span class="line">        lr_model, lr_params, lr_rmse, lr_rmsle = optimize_linear_regression(X_train, X_val, y_train, y_val)</span><br><span class="line">        results[<span class="string">&#x27;linear_regression&#x27;</span>] = &#123;<span class="string">&#x27;model&#x27;</span>: lr_model, <span class="string">&#x27;params&#x27;</span>: lr_params, <span class="string">&#x27;rmse&#x27;</span>: lr_rmse, <span class="string">&#x27;rmsle&#x27;</span>: lr_rmsle&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 比较优化后的模型</span></span><br><span class="line">        best_model_name = compare_optimized_models(results)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用最佳模型生成提交文件</span></span><br><span class="line">        generate_submission_with_best_model(best_model_name)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;模型优化流程完成！&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制流程图的代码（由于Mermaid需要在Markdown中呈现，这里只生成文本文件）</span></span><br><span class="line">        generate_flow_diagrams()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;模型优化过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_flow_diagrams</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    生成各算法的流程图文本文件</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 决策树流程图</span></span><br><span class="line">    dt_flow = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">```mermaid</span></span><br><span class="line"><span class="string">flowchart TD</span></span><br><span class="line"><span class="string">    A[开始] --&gt; B[加载数据]</span></span><br><span class="line"><span class="string">    B --&gt; C[数据预处理]</span></span><br><span class="line"><span class="string">    C --&gt; D[特征缩放]</span></span><br><span class="line"><span class="string">    D --&gt; E[定义参数网格]</span></span><br><span class="line"><span class="string">    E --&gt; F[创建决策树基础模型]</span></span><br><span class="line"><span class="string">    F --&gt; G[使用GridSearchCV进行网格搜索]</span></span><br><span class="line"><span class="string">    G --&gt; H[获取最佳参数]</span></span><br><span class="line"><span class="string">    H --&gt; I[使用最佳参数训练模型]</span></span><br><span class="line"><span class="string">    I --&gt; J[在验证集上评估]</span></span><br><span class="line"><span class="string">    J --&gt; K[计算RMSE和R²]</span></span><br><span class="line"><span class="string">    K --&gt; K1[计算RMSLE（竞赛评估指标）]</span></span><br><span class="line"><span class="string">    K1 --&gt; L[绘制特征重要性]</span></span><br><span class="line"><span class="string">    L --&gt; M[保存最佳模型]</span></span><br><span class="line"><span class="string">    M --&gt; N[结束]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    style A fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style N fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style G fill:#eeeeee,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style I fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style K1 fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style M fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机森林流程图</span></span><br><span class="line">    rf_flow = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">```mermaid</span></span><br><span class="line"><span class="string">flowchart TD</span></span><br><span class="line"><span class="string">    A[开始] --&gt; B[加载数据]</span></span><br><span class="line"><span class="string">    B --&gt; C[数据预处理]</span></span><br><span class="line"><span class="string">    C --&gt; D[特征缩放]</span></span><br><span class="line"><span class="string">    D --&gt; E[定义参数分布]</span></span><br><span class="line"><span class="string">    E --&gt; F[创建随机森林基础模型]</span></span><br><span class="line"><span class="string">    F --&gt; G[使用RandomizedSearchCV进行随机搜索]</span></span><br><span class="line"><span class="string">    G --&gt; H[获取最佳参数]</span></span><br><span class="line"><span class="string">    H --&gt; I[使用最佳参数训练模型]</span></span><br><span class="line"><span class="string">    I --&gt; J[在验证集上评估]</span></span><br><span class="line"><span class="string">    J --&gt; K[计算RMSE和R²]</span></span><br><span class="line"><span class="string">    K --&gt; K1[计算RMSLE（竞赛评估指标）]</span></span><br><span class="line"><span class="string">    K1 --&gt; L[绘制特征重要性]</span></span><br><span class="line"><span class="string">    L --&gt; M[保存最佳模型]</span></span><br><span class="line"><span class="string">    M --&gt; N[结束]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    style A fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style N fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style G fill:#eeeeee,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style I fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style K1 fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style M fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># XGBoost流程图</span></span><br><span class="line">    xgb_flow = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">```mermaid</span></span><br><span class="line"><span class="string">flowchart TD</span></span><br><span class="line"><span class="string">    A[开始] --&gt; B[加载数据]</span></span><br><span class="line"><span class="string">    B --&gt; C[数据预处理]</span></span><br><span class="line"><span class="string">    C --&gt; D[特征缩放]</span></span><br><span class="line"><span class="string">    D --&gt; E[定义参数网格]</span></span><br><span class="line"><span class="string">    E --&gt; F[创建XGBoost基础模型]</span></span><br><span class="line"><span class="string">    F --&gt; G[使用RandomizedSearchCV进行随机搜索]</span></span><br><span class="line"><span class="string">    G --&gt; H[获取最佳参数]</span></span><br><span class="line"><span class="string">    H --&gt; I[使用最佳参数训练模型]</span></span><br><span class="line"><span class="string">    I --&gt; J[在验证集上评估]</span></span><br><span class="line"><span class="string">    J --&gt; K[计算RMSE和R²]</span></span><br><span class="line"><span class="string">    K --&gt; K1[计算RMSLE（竞赛评估指标）]</span></span><br><span class="line"><span class="string">    K1 --&gt; L[绘制特征重要性]</span></span><br><span class="line"><span class="string">    L --&gt; M[保存最佳模型]</span></span><br><span class="line"><span class="string">    M --&gt; N[结束]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    style A fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style N fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style G fill:#eeeeee,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style I fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style K1 fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style M fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 线性回归流程图</span></span><br><span class="line">    lr_flow = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">```mermaid</span></span><br><span class="line"><span class="string">flowchart TD</span></span><br><span class="line"><span class="string">    A[开始] --&gt; B[加载数据]</span></span><br><span class="line"><span class="string">    B --&gt; C[数据预处理]</span></span><br><span class="line"><span class="string">    C --&gt; D[特征缩放]</span></span><br><span class="line"><span class="string">    D --&gt; F[创建线性回归模型]</span></span><br><span class="line"><span class="string">    F --&gt; I[训练模型]</span></span><br><span class="line"><span class="string">    I --&gt; J[在验证集上评估]</span></span><br><span class="line"><span class="string">    J --&gt; K[计算RMSE和R²]</span></span><br><span class="line"><span class="string">    K --&gt; K1[计算RMSLE（竞赛评估指标）]</span></span><br><span class="line"><span class="string">    K1 --&gt; L[绘制特征系数]</span></span><br><span class="line"><span class="string">    L --&gt; M[保存模型]</span></span><br><span class="line"><span class="string">    M --&gt; N[结束]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    style A fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style N fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style I fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style K1 fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style M fill:#b5ead7,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型比较流程图</span></span><br><span class="line">    compare_flow = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">```mermaid</span></span><br><span class="line"><span class="string">flowchart TD</span></span><br><span class="line"><span class="string">    A[开始] --&gt; B[加载所有优化后的模型]</span></span><br><span class="line"><span class="string">    B --&gt; C[计算每个模型的RMSE]</span></span><br><span class="line"><span class="string">    C --&gt; D[计算每个模型的RMSLE]</span></span><br><span class="line"><span class="string">    D --&gt; E[绘制RMSE比较图]</span></span><br><span class="line"><span class="string">    E --&gt; F[绘制RMSLE比较图]</span></span><br><span class="line"><span class="string">    F --&gt; G[基于RMSLE选择最佳模型]</span></span><br><span class="line"><span class="string">    G --&gt; H[使用最佳模型生成提交文件]</span></span><br><span class="line"><span class="string">    H --&gt; I[结束]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    style A fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style I fill:#f9d5e5,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style D fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style F fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">    style G fill:#ffcc99,stroke:#333,stroke-width:2px</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存流程图文本</span></span><br><span class="line">    os.makedirs(<span class="string">&#x27;flowcharts&#x27;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;flowcharts/decision_tree_flow.md&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(dt_flow)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;flowcharts/random_forest_flow.md&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(rf_flow)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;flowcharts/xgboost_flow.md&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(xgb_flow)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;flowcharts/linear_regression_flow.md&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(lr_flow)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;flowcharts/model_comparison_flow.md&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(compare_flow)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;流程图文本文件已生成在 &#x27;flowcharts&#x27; 文件夹中&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main() </span><br></pre></td></tr></table></figure>
<h2 id="六、模型应用">六、模型应用</h2>
<h3 id="6-1-最终模型选择">6.1 最终模型选择</h3>
<p>XGBoost</p>
<h3 id="6-2-模型实际应用场景">6.2 模型实际应用场景</h3>
<p>该预测模型可应用于以下场景：</p>
<ol>
<li>健身应用中的卡路里消耗预测功能</li>
<li>智能手表、手环等可穿戴设备的能量消耗算法</li>
<li>个性化健身计划制定工具</li>
<li>健康管理系统的锻炼评估组件</li>
</ol>
<h2 id="七、数据分析结论">七、数据分析结论</h2>
<h3 id="7-1-主要发现">7.1 主要发现</h3>
<p>通过本项目的数据分析和建模，我们得出以下主要发现：同上面</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515153934775.png" alt=""></p>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文显示</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 尝试设置中文字体</span></span><br><span class="line">    font = FontProperties(fname=<span class="string">r&quot;C:\Windows\Fonts\SimHei.ttf&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  </span><br><span class="line">    plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;警告: 未能设置中文字体，图表中的中文可能显示为方块&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型性能数据</span></span><br><span class="line">models = [<span class="string">&#x27;XGBoost&#x27;</span>, <span class="string">&#x27;随机森林&#x27;</span>, <span class="string">&#x27;决策树&#x27;</span>, <span class="string">&#x27;线性回归&#x27;</span>]  <span class="comment"># 调整顺序，确保随机森林显示正确</span></span><br><span class="line">rmse_scores = [<span class="number">3.6246</span>, <span class="number">3.7526</span>, <span class="number">5.9721</span>, <span class="number">11.0588</span>]  <span class="comment"># 对应调整顺序</span></span><br><span class="line">r2_scores = [<span class="number">0.9966</span>, <span class="number">0.9964</span>, <span class="number">0.9908</span>, <span class="number">0.9684</span>]  <span class="comment"># 对应调整顺序</span></span><br><span class="line">rmsle_scores = [<span class="number">0.0622</span>, <span class="number">0.0627</span>, <span class="number">0.0896</span>, <span class="number">0.5652</span>]  <span class="comment"># 对应调整顺序</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataFrame以便于数据处理</span></span><br><span class="line">results_df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;模型&#x27;</span>: models,</span><br><span class="line">    <span class="string">&#x27;RMSE&#x27;</span>: rmse_scores,</span><br><span class="line">    <span class="string">&#x27;R平方&#x27;</span>: r2_scores,</span><br><span class="line">    <span class="string">&#x27;RMSLE (竞赛评估指标)&#x27;</span>: rmsle_scores</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印比较表格</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型性能比较表：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(results_df.to_string(index=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找出每个指标的最佳模型</span></span><br><span class="line">best_rmse_model = models[np.argmin(rmse_scores)]</span><br><span class="line">best_r2_model = models[np.argmax(r2_scores)]</span><br><span class="line">best_rmsle_model = models[np.argmin(rmsle_scores)]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n各指标最佳模型：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;RMSE 最低的模型: <span class="subst">&#123;best_rmse_model&#125;</span> (RMSE = <span class="subst">&#123;<span class="built_in">min</span>(rmse_scores):<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R平方 最高的模型: <span class="subst">&#123;best_r2_model&#125;</span> (R平方 = <span class="subst">&#123;<span class="built_in">max</span>(r2_scores):<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;RMSLE 最低的模型: <span class="subst">&#123;best_rmsle_model&#125;</span> (RMSLE = <span class="subst">&#123;<span class="built_in">min</span>(rmsle_scores):<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算各模型的综合排名</span></span><br><span class="line"><span class="comment"># 为每个指标计算排名（RMSE和RMSLE越低越好，R²越高越好）</span></span><br><span class="line">rmse_rank = np.argsort(rmse_scores).argsort()</span><br><span class="line">r2_rank = np.argsort(-np.array(r2_scores)).argsort()  <span class="comment"># 负号使得R²越高排名越靠前</span></span><br><span class="line">rmsle_rank = np.argsort(rmsle_scores).argsort()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算平均排名</span></span><br><span class="line">avg_rank = (rmse_rank + r2_rank + rmsle_rank) / <span class="number">3.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加排名信息到DataFrame</span></span><br><span class="line">results_df[<span class="string">&#x27;RMSE排名&#x27;</span>] = rmse_rank + <span class="number">1</span>  <span class="comment"># +1使排名从1开始</span></span><br><span class="line">results_df[<span class="string">&#x27;R平方排名&#x27;</span>] = r2_rank + <span class="number">1</span></span><br><span class="line">results_df[<span class="string">&#x27;RMSLE排名&#x27;</span>] = rmsle_rank + <span class="number">1</span></span><br><span class="line">results_df[<span class="string">&#x27;平均排名&#x27;</span>] = avg_rank + <span class="number">1</span></span><br><span class="line">results_df = results_df.sort_values(<span class="string">&#x27;平均排名&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n综合排名（考虑所有指标）：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(results_df[[<span class="string">&#x27;模型&#x27;</span>, <span class="string">&#x27;RMSE排名&#x27;</span>, <span class="string">&#x27;R平方排名&#x27;</span>, <span class="string">&#x27;RMSLE排名&#x27;</span>, <span class="string">&#x27;平均排名&#x27;</span>]].to_string(index=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义更好的颜色方案</span></span><br><span class="line">colors = [<span class="string">&#x27;#3498db&#x27;</span>, <span class="string">&#x27;#2ecc71&#x27;</span>, <span class="string">&#x27;#9b59b6&#x27;</span>, <span class="string">&#x27;#e74c3c&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化比较</span></span><br><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">12</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. RMSE比较</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">ax1 = sns.barplot(x=<span class="string">&#x27;模型&#x27;</span>, y=<span class="string">&#x27;RMSE&#x27;</span>, data=results_df, hue=<span class="string">&#x27;模型&#x27;</span>, palette=colors, legend=<span class="literal">False</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;各模型RMSE比较（越低越好）&#x27;</span>, fontproperties=font, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;RMSE&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;模型&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取Y轴的最大值，用于计算标签位置</span></span><br><span class="line">y_max = <span class="built_in">max</span>(rmse_scores) * <span class="number">1.15</span></span><br><span class="line">plt.ylim(<span class="number">0</span>, y_max)  <span class="comment"># 设置Y轴范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在柱状图上添加数值标签 - 统一在柱子上方</span></span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(rmse_scores):</span><br><span class="line">    <span class="comment"># 统一在柱子上方显示标签</span></span><br><span class="line">    label_height = v + (y_max * <span class="number">0.02</span>)  <span class="comment"># 柱子顶部上方2%的位置</span></span><br><span class="line">    ax1.text(i, label_height, <span class="string">f&#x27;<span class="subst">&#123;v:<span class="number">.4</span>f&#125;</span>&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. R平方比较</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax2 = sns.barplot(x=<span class="string">&#x27;模型&#x27;</span>, y=<span class="string">&#x27;R平方&#x27;</span>, data=results_df, hue=<span class="string">&#x27;模型&#x27;</span>, palette=colors, legend=<span class="literal">False</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;各模型R平方比较（越高越好）&#x27;</span>, fontproperties=font, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;R平方&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;模型&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置Y轴范围，从0.95开始以突出差异</span></span><br><span class="line">y_min_r2 = <span class="built_in">min</span>(r2_scores) * <span class="number">0.99</span></span><br><span class="line">y_max_r2 = <span class="number">1.001</span></span><br><span class="line">plt.ylim(y_min_r2, y_max_r2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在柱状图上添加数值标签 - 统一在柱子顶部上方</span></span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(r2_scores):</span><br><span class="line">    <span class="comment"># 统一在柱子上方显示标签</span></span><br><span class="line">    label_height = v + (y_max_r2 - v) * <span class="number">0.3</span>  <span class="comment"># 柱子顶部上方</span></span><br><span class="line">    ax2.text(i, label_height, <span class="string">f&#x27;<span class="subst">&#123;v:<span class="number">.4</span>f&#125;</span>&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. RMSLE比较（竞赛评估指标）</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">ax3 = sns.barplot(x=<span class="string">&#x27;模型&#x27;</span>, y=<span class="string">&#x27;RMSLE (竞赛评估指标)&#x27;</span>, data=results_df, hue=<span class="string">&#x27;模型&#x27;</span>, palette=colors, legend=<span class="literal">False</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;各模型RMSLE比较（竞赛评估指标，越低越好）&#x27;</span>, fontproperties=font, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;RMSLE&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;模型&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取Y轴的最大值，用于计算标签位置</span></span><br><span class="line">y_max_rmsle = <span class="built_in">max</span>(rmsle_scores) * <span class="number">1.15</span></span><br><span class="line">plt.ylim(<span class="number">0</span>, y_max_rmsle)  <span class="comment"># 设置Y轴范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在柱状图上添加数值标签 - 统一在柱子上方</span></span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(rmsle_scores):</span><br><span class="line">    <span class="comment"># 统一在柱子上方显示标签</span></span><br><span class="line">    label_height = v + (y_max_rmsle * <span class="number">0.02</span>)  <span class="comment"># 柱子顶部上方2%的位置</span></span><br><span class="line">    ax3.text(i, label_height, <span class="string">f&#x27;<span class="subst">&#123;v:<span class="number">.4</span>f&#125;</span>&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 综合排名比较</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">sorted_df = results_df.sort_values(<span class="string">&#x27;平均排名&#x27;</span>, ascending=<span class="literal">True</span>)</span><br><span class="line">ax4 = sns.barplot(x=<span class="string">&#x27;模型&#x27;</span>, y=<span class="string">&#x27;平均排名&#x27;</span>, data=sorted_df, hue=<span class="string">&#x27;模型&#x27;</span>, palette=colors, legend=<span class="literal">False</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;各模型综合排名（越低越好）&#x27;</span>, fontproperties=font, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;平均排名&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;模型&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置Y轴范围</span></span><br><span class="line">y_max_rank = <span class="number">5</span></span><br><span class="line">plt.ylim(<span class="number">0</span>, y_max_rank)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在柱状图上添加数值标签 - 统一在柱子上方</span></span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(sorted_df[<span class="string">&#x27;平均排名&#x27;</span>]):</span><br><span class="line">    <span class="comment"># 统一在柱子上方显示标签</span></span><br><span class="line">    label_height = v + (y_max_rank * <span class="number">0.05</span>)  <span class="comment"># 柱子顶部上方5%的位置</span></span><br><span class="line">    ax4.text(i, label_height, <span class="string">f&#x27;<span class="subst">&#123;v:<span class="number">.2</span>f&#125;</span>&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加总体标题</span></span><br><span class="line">plt.suptitle(<span class="string">&#x27;卡路里消耗预测模型性能比较&#x27;</span>, fontsize=<span class="number">18</span>, fontproperties=font, y=<span class="number">0.98</span>)</span><br><span class="line">plt.tight_layout(rect=[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0.95</span>])  <span class="comment"># 调整布局，为总标题留出空间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存图表</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;模型性能比较.png&#x27;</span>, dpi=<span class="number">300</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图表</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终结论</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n最终结论：&quot;</span>)</span><br><span class="line">best_model = results_df.iloc[<span class="number">0</span>][<span class="string">&#x27;模型&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;综合各项指标，<span class="subst">&#123;best_model&#125;</span>模型表现最优。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> best_model == <span class="string">&quot;XGBoost&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">具体优势：</span></span><br><span class="line"><span class="string">1. XGBoost模型RMSE最低（3.6246），意味着预测误差最小</span></span><br><span class="line"><span class="string">2. R平方值最高（0.9966），说明模型解释了约99.66%的目标变量方差</span></span><br><span class="line"><span class="string">3. RMSLE值最低（0.0622），在竞赛评估指标上表现最佳</span></span><br><span class="line"><span class="string">4. 综合排名第一</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐在最终提交中使用XGBoost模型预测结果。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">elif</span> best_model == <span class="string">&quot;随机森林&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">具体优势：</span></span><br><span class="line"><span class="string">1. 随机森林模型RMSE仅次于XGBoost（3.7526）</span></span><br><span class="line"><span class="string">2. R平方值接近XGBoost（0.9964）</span></span><br><span class="line"><span class="string">3. RMSLE值仅略高于XGBoost（0.0627）</span></span><br><span class="line"><span class="string">4. 综合排名第二，但与XGBoost非常接近</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐在最终提交中使用随机森林模型预测结果，或与XGBoost模型结果进行集成。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>) </span><br></pre></td></tr></table></figure>
<h3 id="7-2-未来改进方向">7.2 未来改进方向</h3>
<p>本项目还可在以下方面进行改进：</p>
<ol>
<li>收集更多维度的数据，如锻炼类型、强度等</li>
<li>尝试更多高级算法，如神经网络、集成学习等</li>
<li>引入时间序列特征，考虑锻炼连续性的影响</li>
<li>结合领域知识，开发更专业的特征工程方法</li>
</ol>
<p>上周刚搜到神经网络 今天上课就要求写了 哈哈哈哈…</p>
<p>那来看看神经网络代码：</p>
<p>说一下大概干了什么事情：</p>
<ol>
<li>神经网络建模与优化：</li>
</ol>
<ul>
<li>
<p>模型选择：我选择了Scikit-learn库中的MLPRegressor（多层感知机回归器）作为主要的神经网络模型。</p>
</li>
<li>
<p>数据标准化：由于神经网络对输入特征的尺度非常敏感，在将数据送入模型前，我们使用了StandardScaler对所有特征进行了标准化处理。</p>
</li>
<li>
<p>基准建立与调优：首先，我们训练了一个基础配置的神经网络模型，以了解其大致性能。然后，为了找到最优的模型配置，我们采用了网格搜索（GridSearchCV）的方法，对神经网络的关键超参数（如隐藏层结构、激活函数、正则化强度和初始学习率）进行了系统的调优。调优过程中使用了3折交叉验证，并以负均方误差作为评估标准。</p>
</li>
<li>
<p>性能评估：对于调优后的最佳神经网络模型，我们在独立的验证集上评估了其性能，主要关注的指标包括均方根误差（RMSE）、R²决定系数以及均方根对数误差（RMSLE）。脚本中还计算了这些指标，并将它们与一个预先训练好的XGBoost模型的性能进行了对比。</p>
</li>
</ul>
<p>2.结果可视化与分析：为了更直观地理解模型性能，脚本生成了多种可视化图表。包括：</p>
<ul>
<li>
<p>不同模型（基础神经网络、调优后神经网络、XGBoost）在各项评估指标上的对比条形图。</p>
</li>
<li>
<p>调优后神经网络的预测值与实际值的对比散点图。</p>
</li>
<li>
<p>模型预测残差的分布图和残差与预测值的关系图，用于分析模型的偏差和潜在问题。</p>
</li>
</ul>
<p>3.模型应用与输出：最后，利用训练好的最佳神经网络模型和相应的特征缩放器，对测试数据集进行预测，并生成了符合竞赛提交格式要求的CSV文件。</p>
<p>具体分析：</p>
<p><code>train_neural_network</code> 函数</p>
<p>一开始也是数据分割与标准化，这里可以看下面的完整代码，可以说一下的是：神经网络对输入特征的尺度非常敏感。如果特征尺度差异很大，训练过程可能会变得缓慢且不稳定。<code>StandardScaler</code>将每个特征转换为均值为0，标准差为1的分布。<strong>注意</strong>：缩放器（<code>scaler</code>）是在训练集上<code>fit_transform</code>的，然后用同样的缩放器在验证集（以及后续的测试集）上<code>transform</code>，以避免数据泄露。</p>
<h3 id="基线模型训练">基线模型训练</h3>
<p>首先，训练了一个具有基础配置的<code>MLPRegressor</code>，以建立一个性能基准。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># ...</span></span><br><span class="line">    base_nn = MLPRegressor(</span><br><span class="line">        hidden_layer_sizes=(<span class="number">100</span>,),  <span class="comment"># 一个隐藏层，100个神经元</span></span><br><span class="line">        activation=<span class="string">&#x27;relu&#x27;</span>,          <span class="comment"># ReLU激活函数</span></span><br><span class="line">        solver=<span class="string">&#x27;adam&#x27;</span>,              <span class="comment"># Adam优化器</span></span><br><span class="line">        alpha=<span class="number">0.0001</span>,               <span class="comment"># L2正则化参数</span></span><br><span class="line">        max_iter=<span class="number">500</span>,               <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">        early_stopping=<span class="literal">True</span>,        <span class="comment"># 启用早停机制</span></span><br><span class="line">        validation_fraction=<span class="number">0.1</span>,    <span class="comment"># 用于早停的验证集比例</span></span><br><span class="line">        tol=<span class="number">1e-4</span>,                   <span class="comment"># 收敛容忍度</span></span><br><span class="line">        random_state=<span class="number">42</span>,</span><br><span class="line">        verbose=<span class="literal">True</span>                <span class="comment"># 显示训练进度</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    start_time = time.time()</span><br><span class="line">    base_nn.fit(X_train_scaled, y_train)</span><br><span class="line">    base_training_time = time.time() - start_time</span><br><span class="line">    </span><br><span class="line">    y_pred_base = base_nn.predict(X_val_scaled)</span><br><span class="line">    base_mse = mean_squared_error(y_val, y_pred_base)</span><br><span class="line">    base_rmse = np.sqrt(base_mse)</span><br><span class="line">    base_mae = mean_absolute_error(y_val, y_pred_base)</span><br><span class="line">    base_r2 = r2_score(y_val, y_pred_base)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;</span></span><br><span class="line"><span class="string">基础神经网络模型评估结果:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  均方根误差 (RMSE): <span class="subst">&#123;base_rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  R² 分数: <span class="subst">&#123;base_r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p>关键参数解释：</p>
<ul>
<li><code>hidden_layer_sizes=(100,)</code>: 定义了一个包含100个神经元的隐藏层。</li>
<li><code>activation='relu'</code>: 使用ReLU作为激活函数，它有助于缓解梯度消失问题。</li>
<li><code>solver='adam'</code>: Adam是一种高效的优化算法。</li>
<li><code>alpha=0.0001</code>: L2正则化参数，用于防止过拟合。</li>
<li><code>max_iter=500</code>: 最大迭代次数。</li>
<li><code>early_stopping=True</code>: 早停机制，当验证集性能不再提升时停止训练，防止过拟合。</li>
</ul>
<p>训练完成后，模型在验证集上进行评估，计算RMSE（均方根误差）和R²（决定系数）等指标。</p>
<h3 id="追求卓越：超参数调优-GridSearchCV">追求卓越：超参数调优 (<code>GridSearchCV</code>)</h3>
<p>为了获得更好的性能，脚本使用<code>GridSearchCV</code>进行超参数调优。这会自动尝试参数网格中的不同组合，并通过交叉验证找到最佳配置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ...</span></span><br><span class="line">   param_grid = &#123;</span><br><span class="line">       <span class="string">&#x27;hidden_layer_sizes&#x27;</span>: [(<span class="number">50</span>,), (<span class="number">100</span>,), (<span class="number">50</span>, <span class="number">25</span>)],  <span class="comment"># 不同的网络结构</span></span><br><span class="line">       <span class="string">&#x27;activation&#x27;</span>: [<span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;tanh&#x27;</span>],                   <span class="comment"># 不同的激活函数</span></span><br><span class="line">       <span class="string">&#x27;alpha&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>],                   <span class="comment"># 不同的正则化强度</span></span><br><span class="line">       <span class="string">&#x27;learning_rate_init&#x27;</span>: [<span class="number">0.001</span>, <span class="number">0.01</span>]               <span class="comment"># 不同的学习率</span></span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   nn_model = MLPRegressor(</span><br><span class="line">       solver=<span class="string">&#x27;adam&#x27;</span>, max_iter=<span class="number">500</span>, early_stopping=<span class="literal">True</span>,</span><br><span class="line">       validation_fraction=<span class="number">0.1</span>, tol=<span class="number">1e-4</span>, random_state=<span class="number">42</span>, verbose=<span class="literal">False</span></span><br><span class="line">   )</span><br><span class="line">   </span><br><span class="line">   grid_search = GridSearchCV(</span><br><span class="line">       estimator=nn_model, param_grid=param_grid, cv=<span class="number">3</span>,</span><br><span class="line">       scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>, n_jobs=-<span class="number">1</span>, verbose=<span class="number">2</span></span><br><span class="line">   )</span><br><span class="line">   </span><br><span class="line">   grid_search.fit(X_train_scaled, y_train)</span><br><span class="line">   </span><br><span class="line">   best_params = grid_search.best_params_</span><br><span class="line">   best_model = grid_search.best_estimator_</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">f&quot;最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">   <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p><code>GridSearchCV</code>会尝试<code>param_grid</code>中定义的所有超参数组合。这里：</p>
<ul>
<li><code>cv=3</code>: 表示使用3折交叉验证。</li>
<li><code>scoring='neg_mean_squared_error'</code>: 评估指标为负均方误差（因为GridSearchCV试图最大化得分，而我们希望最小化MSE）。</li>
<li><code>n_jobs=-1</code>: 使用所有可用的CPU核心并行计算。</li>
</ul>
<h3 id="最佳模型评估与比较">最佳模型评估与比较</h3>
<p>找到最佳超参数后，用最佳模型<code>best_model</code>在验证集上进行预测和评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ...</span></span><br><span class="line">    y_pred_best = best_model.predict(X_val_scaled)</span><br><span class="line">    best_mse = mean_squared_error(y_val, y_pred_best)</span><br><span class="line">    best_rmse = np.sqrt(best_mse)</span><br><span class="line">    best_mae = mean_absolute_error(y_val, y_pred_best)</span><br><span class="line">    best_r2 = r2_score(y_val, y_pred_best)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算RMSLE (Root Mean Squared Logarithmic Error)</span></span><br><span class="line">    <span class="comment"># RMSLE = sqrt( (1/n) * sum( (log(pred_i + 1) - log(actual_i + 1))^2 ) )</span></span><br><span class="line">    <span class="comment"># 添加1是为了避免log(0)的问题，并且因为卡路里消耗量通常是正数</span></span><br><span class="line">    base_rmsle = np.sqrt(np.mean(np.power(np.log1p(y_val) - np.log1p(y_pred_base), <span class="number">2</span>))) <span class="comment"># 修正：y_val和y_pred_base都应+1</span></span><br><span class="line">    best_rmsle = np.sqrt(np.mean(np.power(np.log1p(y_val) - np.log1p(y_pred_best), <span class="number">2</span>))) <span class="comment"># 修正：y_val和y_pred_best都应+1</span></span><br><span class="line">    <span class="comment"># 更正后的RMSLE计算 (如脚本中所示，但y_pred_base也应+1):</span></span><br><span class="line">    <span class="comment"># base_rmsle = np.sqrt(np.mean(np.power(np.log1p(y_val + 1) - np.log1p(y_pred_base + 1), 2)))</span></span><br><span class="line">    <span class="comment"># best_rmsle = np.sqrt(np.mean(np.power(np.log1p(y_val + 1) - np.log1p(y_pred_best + 1), 2)))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;</span></span><br><span class="line"><span class="string">最佳神经网络模型评估结果:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  均方根误差 (RMSE): <span class="subst">&#123;best_rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  R² 分数: <span class="subst">&#123;best_r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p>我把前面四个模型最好的模型也就是XGBoost与之对比,引入了<code>XGBOOST_RMSE</code>, <code>XGBOOST_R2</code>, <code>XGBOOST_RMSLE</code>这些常量，它们代表了一个预先训练好的XGBoost模型的性能指标。这允许我将神经网络模型的性能与一个强大的基准模型进行比较。RMSLE（均方根对数误差）是另一个重要的回归评估指标，尤其适用于目标变量数量级跨度较大或我们更关注预测百分比误差的情况。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528124744490.png" alt="image-20250528124744490"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528124806904.png" alt="image-20250528124806904"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528124835120.png" alt="image-20250528124835120"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528124855657.png" alt="image-20250528124855657"></p>
<h3 id="深入洞察：预测结果可视化">深入洞察：预测结果可视化</h3>
<p>为了更深入地理解模型的行为，我做了以下可视化图表：</p>
<ol>
<li><strong>预测值 vs. 实际值</strong>:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ...</span></span><br><span class="line">   <span class="comment"># 随机选择100个样本点进行可视化</span></span><br><span class="line">   sample_indices = np.random.choice(<span class="built_in">len</span>(y_val), <span class="built_in">min</span>(<span class="number">100</span>, <span class="built_in">len</span>(y_val)), replace=<span class="literal">False</span>)</span><br><span class="line">   y_val_sample = y_val.iloc[sample_indices]</span><br><span class="line">   y_pred_sample = y_pred_best[sample_indices]</span><br><span class="line">   </span><br><span class="line">   plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">   plt.scatter(y_val_sample, y_pred_sample, alpha=<span class="number">0.7</span>)</span><br><span class="line">   plt.plot([y_val_sample.<span class="built_in">min</span>(), y_val_sample.<span class="built_in">max</span>()], [y_val_sample.<span class="built_in">min</span>(), y_val_sample.<span class="built_in">max</span>()], <span class="string">&#x27;r--&#x27;</span>) <span class="comment"># 对角线</span></span><br><span class="line">   <span class="comment"># ... 设置标题和标签 ...</span></span><br><span class="line">   show_figure(plt.gcf())</span><br><span class="line">   <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528125033313.png" alt="image-20250528125033313"></p>
<p><strong>残差分布</strong>: 残差是实际值与预测值之差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ...</span></span><br><span class="line">   residuals = y_val - y_pred_best</span><br><span class="line">   plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">   sns.histplot(residuals, kde=<span class="literal">True</span>) <span class="comment"># 直方图和核密度估计</span></span><br><span class="line">   plt.axvline(x=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>) <span class="comment"># 零点线</span></span><br><span class="line">   <span class="comment"># ... 设置标题和标签 ...</span></span><br><span class="line">   show_figure(plt.gcf())</span><br><span class="line">   <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528125132720.png" alt="image-20250528125132720"></p>
<p><strong>残差 vs. 预测值</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.scatter(y_pred_best, residuals, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.axhline(y=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>) <span class="comment"># 水平零线</span></span><br><span class="line"><span class="comment"># ... 设置标题和标签 ...</span></span><br><span class="line">show_figure(plt.gcf())</span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528125224921.png" alt="image-20250528125224921"></p>
<h3 id="模型保存">模型保存</h3>
<p>训练和调优完成后，将最佳模型和特征缩放器保存到磁盘，以便将来重用，而无需重新训练。(详细见下面完整代码) 后面还有一个生成竞赛的提交文件的代码</p>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">卡路里消耗预测 - 神经网络模型实现</span></span><br><span class="line"><span class="string">本代码使用Scikit-learn的MLPRegressor实现神经网络模型预测锻炼期间燃烧的卡路里</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score, mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager <span class="keyword">as</span> fm</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="comment"># XGBoost模型的性能指标（基于之前的训练结果）</span></span><br><span class="line">XGBOOST_RMSE = <span class="number">3.6246</span>    <span class="comment"># XGBoost模型的均方根误差</span></span><br><span class="line">XGBOOST_R2 = <span class="number">0.9966</span>      <span class="comment"># XGBoost模型的R²值</span></span><br><span class="line">XGBOOST_RMSLE = <span class="number">0.0622</span>   <span class="comment"># XGBoost模型的均方根对数误差</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文显示</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 使用更可靠的方式设置中文字体</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.font_manager <span class="keyword">as</span> fm</span><br><span class="line">    <span class="keyword">import</span> platform</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 常见中文字体列表，按照可用性顺序排列</span></span><br><span class="line">    chinese_fonts = [</span><br><span class="line">        <span class="string">&#x27;SimHei&#x27;</span>, <span class="string">&#x27;Microsoft YaHei&#x27;</span>, <span class="string">&#x27;SimSun&#x27;</span>, <span class="string">&#x27;STSong&#x27;</span>, <span class="string">&#x27;WenQuanYi Zen Hei&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;AR PL UMing CN&#x27;</span>, <span class="string">&#x27;AR PL UKai CN&#x27;</span>, <span class="string">&#x27;KaiTi&#x27;</span>, <span class="string">&#x27;FangSong&#x27;</span></span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置rcParams</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查已有字体</span></span><br><span class="line">    system_fonts = <span class="built_in">set</span>([f.name <span class="keyword">for</span> f <span class="keyword">in</span> fm.fontManager.ttflist])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;系统内可用字体数量: <span class="subst">&#123;<span class="built_in">len</span>(system_fonts)&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 查找可用的中文字体</span></span><br><span class="line">    available_chinese_font = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> font <span class="keyword">in</span> chinese_fonts:</span><br><span class="line">        <span class="keyword">if</span> font <span class="keyword">in</span> system_fonts:</span><br><span class="line">            available_chinese_font = font</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;找到可用中文字体: <span class="subst">&#123;font&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> available_chinese_font:</span><br><span class="line">        plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [available_chinese_font] + plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]</span><br><span class="line">        CHINESE_FONTS_AVAILABLE = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 尝试重建字体缓存</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未找到中文字体，尝试重建字体缓存...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> _rebuild</span><br><span class="line">            _rebuild()</span><br><span class="line">            <span class="comment"># 重新检查字体</span></span><br><span class="line">            system_fonts = <span class="built_in">set</span>([f.name <span class="keyword">for</span> f <span class="keyword">in</span> fm.fontManager.ttflist])</span><br><span class="line">            <span class="keyword">for</span> font <span class="keyword">in</span> chinese_fonts:</span><br><span class="line">                <span class="keyword">if</span> font <span class="keyword">in</span> system_fonts:</span><br><span class="line">                    available_chinese_font = font</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;重建缓存后找到可用中文字体: <span class="subst">&#123;font&#125;</span>&quot;</span>)</span><br><span class="line">                    plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [available_chinese_font] + plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]</span><br><span class="line">                    CHINESE_FONTS_AVAILABLE = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;重建字体缓存失败，图表中文将使用FontProperties方式处理&quot;</span>)</span><br><span class="line">            CHINESE_FONTS_AVAILABLE = <span class="literal">False</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># 如果设置失败，使用默认字体，不显示中文</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;字体设置失败，错误信息: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 恢复默认设置</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;Arial&#x27;</span>]</span><br><span class="line">    <span class="comment"># 修改图表标题和标签为英文</span></span><br><span class="line">    CHINESE_FONTS_AVAILABLE = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置matplotlib参数，使图表直接显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;interactive&#x27;</span>] = <span class="literal">True</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置默认图表大小</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.dpi&#x27;</span>] = <span class="number">100</span>  <span class="comment"># 设置默认DPI</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子，确保结果可重现</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一个辅助函数，用于在条形图上显示数值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_value_labels</span>(<span class="params">ax, spacing=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    在条形图上添加数值标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        ax: matplotlib轴对象</span></span><br><span class="line"><span class="string">        spacing: 标签与条形顶部的距离</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 对于ax中的每个条形</span></span><br><span class="line">    <span class="keyword">for</span> rect <span class="keyword">in</span> ax.patches:</span><br><span class="line">        <span class="comment"># 获取条形的高度</span></span><br><span class="line">        height = rect.get_height()</span><br><span class="line">        <span class="comment"># 在条形顶部添加文本</span></span><br><span class="line">        ax.annotate(<span class="string">f&#x27;<span class="subst">&#123;height:<span class="number">.4</span>f&#125;</span>&#x27;</span>,  <span class="comment"># 文本内容</span></span><br><span class="line">                    xy=(rect.get_x() + rect.get_width() / <span class="number">2</span>, height),  <span class="comment"># 文本位置</span></span><br><span class="line">                    xytext=(<span class="number">0</span>, spacing),  <span class="comment"># 文本偏移</span></span><br><span class="line">                    textcoords=<span class="string">&quot;offset points&quot;</span>,  <span class="comment"># 偏移类型</span></span><br><span class="line">                    ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>)  <span class="comment"># 对齐方式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一个函数，用于显示图表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_figure</span>(<span class="params">fig, filename=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    显示图表</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        fig: matplotlib图表对象</span></span><br><span class="line"><span class="string">        filename: 可选参数，被忽略</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 显示图表</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一个辅助函数，用于在绘图时使用中文字体</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">use_chinese_font</span>(<span class="params">ax, title=<span class="literal">None</span>, xlabel=<span class="literal">None</span>, ylabel=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    为图表设置中文字体</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        ax: matplotlib轴对象</span></span><br><span class="line"><span class="string">        title: 标题文本</span></span><br><span class="line"><span class="string">        xlabel: x轴标签文本</span></span><br><span class="line"><span class="string">        ylabel: y轴标签文本</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 如果没有可用的中文字体，尝试使用FontProperties</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">        <span class="comment"># 尝试几个常用中文字体</span></span><br><span class="line">        font_paths = [</span><br><span class="line">            <span class="comment"># 系统字体路径</span></span><br><span class="line">            <span class="string">&#x27;/usr/share/fonts/truetype/SimHei.ttf&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;/usr/share/fonts/chinese/SimHei.ttf&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;/usr/share/fonts/windows/SimHei.ttf&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc&#x27;</span>,</span><br><span class="line">            <span class="comment"># Windows常用路径</span></span><br><span class="line">            <span class="string">&#x27;C:/Windows/Fonts/SimHei.ttf&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;C:/Windows/Fonts/simhei.ttf&#x27;</span>,</span><br><span class="line">            <span class="comment"># Mac常用路径</span></span><br><span class="line">            <span class="string">&#x27;/Library/Fonts/Arial Unicode.ttf&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;/System/Library/Fonts/PingFang.ttc&#x27;</span></span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 尝试找到可用的字体文件</span></span><br><span class="line">        font_prop = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> font_path <span class="keyword">in</span> font_paths:</span><br><span class="line">            <span class="keyword">if</span> os.path.exists(font_path):</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    font_prop = fm.FontProperties(fname=font_path)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;使用字体文件: <span class="subst">&#123;font_path&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果仍然没有找到字体，使用系统默认字体</span></span><br><span class="line">        <span class="keyword">if</span> font_prop <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;无法找到中文字体文件，将尝试使用系统默认字体&quot;</span>)</span><br><span class="line">            font_prop = fm.FontProperties()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 设置标题和标签</span></span><br><span class="line">        <span class="keyword">if</span> title:</span><br><span class="line">            ax.set_title(title, fontproperties=font_prop)</span><br><span class="line">        <span class="keyword">if</span> xlabel:</span><br><span class="line">            ax.set_xlabel(xlabel, fontproperties=font_prop)</span><br><span class="line">        <span class="keyword">if</span> ylabel:</span><br><span class="line">            ax.set_ylabel(ylabel, fontproperties=font_prop)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果有可用的中文字体，直接设置标题和标签</span></span><br><span class="line">        <span class="keyword">if</span> title:</span><br><span class="line">            ax.set_title(title)</span><br><span class="line">        <span class="keyword">if</span> xlabel:</span><br><span class="line">            ax.set_xlabel(xlabel)</span><br><span class="line">        <span class="keyword">if</span> ylabel:</span><br><span class="line">            ax.set_ylabel(ylabel)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">use_sampling=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始卡路里消耗预测神经网络模型训练...&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Starting calorie consumption prediction neural network model training...&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. 数据获取</span></span><br><span class="line">    train_data, test_data = load_data()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 数据预处理</span></span><br><span class="line">    train_data = preprocess_data(train_data)</span><br><span class="line">    test_data = preprocess_data(test_data, is_train=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 特征工程</span></span><br><span class="line">    train_data = feature_engineering(train_data)</span><br><span class="line">    test_data = feature_engineering(test_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 特征与目标变量分离</span></span><br><span class="line">    X_train, y_train = train_data.drop(<span class="string">&#x27;Calories&#x27;</span>, axis=<span class="number">1</span>), train_data[<span class="string">&#x27;Calories&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. 神经网络模型训练和评估</span></span><br><span class="line">    sample_limit = <span class="number">100000</span> <span class="keyword">if</span> use_sampling <span class="keyword">else</span> <span class="literal">None</span>  <span class="comment"># 如果使用采样，设置为10万条记录</span></span><br><span class="line">    best_nn_model, best_nn_score, best_r2, best_rmsle = train_neural_network(X_train, y_train, sample_limit)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 使用最佳模型进行预测并生成提交文件</span></span><br><span class="line">    generate_submission(best_nn_model, test_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 7. 输出神经网络与XGBoost模型的比较结果</span></span><br><span class="line">    <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n=== 神经网络与XGBoost模型性能比较 ===&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;模型性能指标比较：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;模型名称&#x27;</span>:&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;RMSE&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;R²&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;RMSLE&#x27;</span>:&lt;<span class="number">10</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n=== Neural Network vs XGBoost Model Performance Comparison ===&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Model Performance Metrics:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;Model Name&#x27;</span>:&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;RMSE&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;R²&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;RMSLE&#x27;</span>:&lt;<span class="number">10</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">50</span>)</span><br><span class="line">    <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;神经网络(调优后)&#x27;</span>:&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;best_nn_score:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;best_r2:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;best_rmsle:&lt;<span class="number">10.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;XGBoost&#x27;</span>:&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;XGBOOST_RMSE:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;XGBOOST_R2:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;XGBOOST_RMSLE:&lt;<span class="number">10.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;Neural Network (Tuned)&#x27;</span>:&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;best_nn_score:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;best_r2:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;best_rmsle:&lt;<span class="number">10.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;XGBoost&#x27;</span>:&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;XGBOOST_RMSE:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;XGBOOST_R2:&lt;<span class="number">10.4</span>f&#125;</span> <span class="subst">&#123;XGBOOST_RMSLE:&lt;<span class="number">10.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">50</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 比较结果分析</span></span><br><span class="line">    nn_better_rmse = best_nn_score &lt; XGBOOST_RMSE</span><br><span class="line">    nn_better_r2 = best_r2 &gt; XGBOOST_R2</span><br><span class="line">    nn_better_rmsle = best_rmsle &lt; XGBOOST_RMSLE</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n结论:&quot;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&quot;\nConclusion:&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> nn_better_rmse <span class="keyword">and</span> nn_better_r2 <span class="keyword">and</span> nn_better_rmsle:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;神经网络模型在所有指标上均优于XGBoost模型。&quot;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&quot;Neural Network model outperforms XGBoost model on all metrics.&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> nn_better_rmse <span class="keyword">and</span> <span class="keyword">not</span> nn_better_r2 <span class="keyword">and</span> <span class="keyword">not</span> nn_better_rmsle:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;XGBoost模型在所有指标上均优于神经网络模型。&quot;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&quot;XGBoost model outperforms Neural Network model on all metrics.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;模型性能比较：&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;- RMSE: <span class="subst">&#123;<span class="string">&#x27;神经网络&#x27;</span> <span class="keyword">if</span> nn_better_rmse <span class="keyword">else</span> <span class="string">&#x27;XGBoost&#x27;</span>&#125;</span> 模型表现更好&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;- R²: <span class="subst">&#123;<span class="string">&#x27;神经网络&#x27;</span> <span class="keyword">if</span> nn_better_r2 <span class="keyword">else</span> <span class="string">&#x27;XGBoost&#x27;</span>&#125;</span> 模型表现更好&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;- RMSLE: <span class="subst">&#123;<span class="string">&#x27;神经网络&#x27;</span> <span class="keyword">if</span> nn_better_rmsle <span class="keyword">else</span> <span class="string">&#x27;XGBoost&#x27;</span>&#125;</span> 模型表现更好&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Model performance comparison:&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;- RMSE: <span class="subst">&#123;<span class="string">&#x27;Neural Network&#x27;</span> <span class="keyword">if</span> nn_better_rmse <span class="keyword">else</span> <span class="string">&#x27;XGBoost&#x27;</span>&#125;</span> model performs better&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;- R²: <span class="subst">&#123;<span class="string">&#x27;Neural Network&#x27;</span> <span class="keyword">if</span> nn_better_r2 <span class="keyword">else</span> <span class="string">&#x27;XGBoost&#x27;</span>&#125;</span> model performs better&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;- RMSLE: <span class="subst">&#123;<span class="string">&#x27;Neural Network&#x27;</span> <span class="keyword">if</span> nn_better_rmsle <span class="keyword">else</span> <span class="string">&#x27;XGBoost&#x27;</span>&#125;</span> model performs better&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n卡路里消耗预测神经网络模型训练完成！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\nCalorie consumption prediction neural network model training completed!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载训练集和测试集数据，支持本地路径和Kaggle路径</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (训练数据, 测试数据)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在加载数据...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义可能的数据路径</span></span><br><span class="line">        possible_train_paths = [</span><br><span class="line">            <span class="string">&#x27;/kaggle/input/playground-series-s5e5/train.csv&#x27;</span>,  <span class="comment"># Kaggle路径</span></span><br><span class="line">            <span class="string">&#x27;train.csv&#x27;</span>  <span class="comment"># 本地路径</span></span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        possible_test_paths = [</span><br><span class="line">            <span class="string">&#x27;/kaggle/input/playground-series-s5e5/test.csv&#x27;</span>,  <span class="comment"># Kaggle路径</span></span><br><span class="line">            <span class="string">&#x27;test.csv&#x27;</span>  <span class="comment"># 本地路径</span></span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 尝试加载训练数据</span></span><br><span class="line">        train_data = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> path <span class="keyword">in</span> possible_train_paths:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">                    train_data = pd.read_csv(path)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;成功从 <span class="subst">&#123;path&#125;</span> 加载训练数据&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;尝试从 <span class="subst">&#123;path&#125;</span> 加载训练数据失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> train_data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;无法找到训练数据文件，请确保train.csv存在于正确位置&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 尝试加载测试数据</span></span><br><span class="line">        test_data = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> path <span class="keyword">in</span> possible_test_paths:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">                    test_data = pd.read_csv(path)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;成功从 <span class="subst">&#123;path&#125;</span> 加载测试数据&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;尝试从 <span class="subst">&#123;path&#125;</span> 加载测试数据失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> test_data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;无法找到测试数据文件，请确保test.csv存在于正确位置&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;训练集大小：<span class="subst">&#123;train_data.shape&#125;</span>, 测试集大小：<span class="subst">&#123;test_data.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> train_data, test_data</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;加载数据时出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_data</span>(<span class="params">data, is_train=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对数据进行预处理</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 需要处理的数据</span></span><br><span class="line"><span class="string">        is_train (bool): 是否为训练数据</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        DataFrame: 预处理后的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行数据预处理...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建数据副本，避免修改原始数据</span></span><br><span class="line">        df = data.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示数据基本信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n数据基本信息:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(df.info())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示数据统计摘要</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n数据统计摘要:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(df.describe())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检查缺失值</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n检查缺失值:&quot;</span>)</span><br><span class="line">        missing_values = df.isnull().<span class="built_in">sum</span>()</span><br><span class="line">        <span class="built_in">print</span>(missing_values[missing_values &gt; <span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理缺失值（如果有）</span></span><br><span class="line">        <span class="keyword">if</span> df.isnull().<span class="built_in">sum</span>().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 对数值型特征使用均值填充，分类特征使用众数填充</span></span><br><span class="line">            num_features = df.select_dtypes(include=[<span class="string">&#x27;float64&#x27;</span>, <span class="string">&#x27;int64&#x27;</span>]).columns</span><br><span class="line">            cat_features = df.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> num_features:</span><br><span class="line">                <span class="keyword">if</span> df[col].isnull().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">                    df[col].fillna(df[col].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> cat_features:</span><br><span class="line">                <span class="keyword">if</span> df[col].isnull().<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">                    df[col].fillna(df[col].mode()[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 性别编码：将性别特征转换为数值</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Sex&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            df[<span class="string">&#x27;Sex&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 删除ID列，因为它不是预测的特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;id&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            df = df.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示处理后的数据信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n预处理后的数据信息:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(df.info())</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> df</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;数据预处理过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征工程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_engineering</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建新特征以提高模型性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data (DataFrame): 预处理后的数据</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        DataFrame: 包含新特征的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行特征工程...&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程前数据形状: <span class="subst">&#123;data.shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建数据副本</span></span><br><span class="line">        df = data.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录原始特征列表</span></span><br><span class="line">        original_features = df.columns.tolist()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 创建BMI特征（体重指数）</span></span><br><span class="line">        df[<span class="string">&#x27;BMI&#x27;</span>] = df[<span class="string">&#x27;Weight&#x27;</span>] / ((df[<span class="string">&#x27;Height&#x27;</span>]/<span class="number">100</span>) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 创建心率与年龄的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Heart_Rate_Age_Ratio&#x27;</span>] = df[<span class="string">&#x27;Heart_Rate&#x27;</span>] / df[<span class="string">&#x27;Age&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 创建锻炼强度指标</span></span><br><span class="line">        df[<span class="string">&#x27;Exercise_Intensity&#x27;</span>] = df[<span class="string">&#x27;Heart_Rate&#x27;</span>] * df[<span class="string">&#x27;Duration&#x27;</span>] / <span class="number">100</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 创建体温与心率的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Temp_Heart_Ratio&#x27;</span>] = df[<span class="string">&#x27;Body_Temp&#x27;</span>] / df[<span class="string">&#x27;Heart_Rate&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 体重与身高的比率</span></span><br><span class="line">        df[<span class="string">&#x27;Weight_Height_Ratio&#x27;</span>] = df[<span class="string">&#x27;Weight&#x27;</span>] / (df[<span class="string">&#x27;Height&#x27;</span>]/<span class="number">100</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取新创建的特征列表</span></span><br><span class="line">        new_features = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> original_features]</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程完成，创建了 <span class="subst">&#123;<span class="built_in">len</span>(new_features)&#125;</span> 个新特征:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> new_features:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  - <span class="subst">&#123;feature&#125;</span>: 均值=<span class="subst">&#123;df[feature].mean():<span class="number">.4</span>f&#125;</span>, 标准差=<span class="subst">&#123;df[feature].std():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程后数据形状: <span class="subst">&#123;df.shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> df</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;特征工程过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 神经网络模型训练和评估</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_neural_network</span>(<span class="params">X, y, sample_limit=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    训练神经网络模型并评估性能</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X (DataFrame): 特征数据</span></span><br><span class="line"><span class="string">        y (Series): 目标变量（卡路里消耗量）</span></span><br><span class="line"><span class="string">        sample_limit (int, optional): 可选的数据采样限制，如果指定，将随机采样数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (最佳模型, 最佳得分, 最佳R², 最佳RMSLE)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在进行神经网络模型训练和评估...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建保存图形的文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;plots&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;plots&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 可选的数据采样</span></span><br><span class="line">        <span class="keyword">if</span> sample_limit <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">len</span>(X) &gt; sample_limit:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;数据集较大，进行随机采样（<span class="subst">&#123;sample_limit&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(X)&#125;</span>条记录）...&quot;</span>)</span><br><span class="line">            sample_idx = np.random.choice(<span class="built_in">len</span>(X), sample_limit, replace=<span class="literal">False</span>)</span><br><span class="line">            X = X.iloc[sample_idx].copy()</span><br><span class="line">            y = y.iloc[sample_idx].copy()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;采样后数据形状: X=<span class="subst">&#123;X.shape&#125;</span>, y=<span class="subst">&#123;<span class="built_in">len</span>(y)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;使用完整数据集: X=<span class="subst">&#123;X.shape&#125;</span>, y=<span class="subst">&#123;<span class="built_in">len</span>(y)&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割数据为训练集和验证集</span></span><br><span class="line">        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征缩放（神经网络对特征缩放非常敏感）</span></span><br><span class="line">        scaler = StandardScaler()</span><br><span class="line">        X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">        X_val_scaled = scaler.transform(X_val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存特征名称，用于后续分析</span></span><br><span class="line">        feature_names = X.columns.tolist()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 首先创建一个基础神经网络模型，了解性能基线</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n训练基础神经网络模型...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建基础神经网络模型</span></span><br><span class="line">        <span class="comment"># hidden_layer_sizes=(100,): 一个隐藏层，包含100个神经元</span></span><br><span class="line">        <span class="comment"># activation=&#x27;relu&#x27;: 使用ReLU激活函数，这是目前最常用的激活函数，计算效率高且能解决梯度消失问题</span></span><br><span class="line">        <span class="comment"># solver=&#x27;adam&#x27;: 使用Adam优化器，一种自适应学习率的优化算法，适合大多数问题</span></span><br><span class="line">        <span class="comment"># alpha=0.0001: L2正则化参数，用于防止过拟合</span></span><br><span class="line">        <span class="comment"># max_iter=500: 最大迭代次数，增加以确保收敛</span></span><br><span class="line">        <span class="comment"># early_stopping=True: 启用早停机制，在验证集性能不再提升时停止训练</span></span><br><span class="line">        <span class="comment"># validation_fraction=0.1: 用于早停的验证集比例</span></span><br><span class="line">        <span class="comment"># tol=1e-4: 收敛容忍度，增加可以放宽收敛条件</span></span><br><span class="line">        <span class="comment"># random_state=42: 随机种子，确保结果可重现</span></span><br><span class="line">        base_nn = MLPRegressor(</span><br><span class="line">            hidden_layer_sizes=(<span class="number">100</span>,),  <span class="comment"># 一个隐藏层，100个神经元</span></span><br><span class="line">            activation=<span class="string">&#x27;relu&#x27;</span>,          <span class="comment"># ReLU激活函数</span></span><br><span class="line">            solver=<span class="string">&#x27;adam&#x27;</span>,              <span class="comment"># Adam优化器</span></span><br><span class="line">            alpha=<span class="number">0.0001</span>,               <span class="comment"># L2正则化参数</span></span><br><span class="line">            max_iter=<span class="number">500</span>,               <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">            early_stopping=<span class="literal">True</span>,        <span class="comment"># 启用早停机制</span></span><br><span class="line">            validation_fraction=<span class="number">0.1</span>,    <span class="comment"># 用于早停的验证集比例</span></span><br><span class="line">            tol=<span class="number">1e-4</span>,                   <span class="comment"># 收敛容忍度</span></span><br><span class="line">            random_state=<span class="number">42</span>,</span><br><span class="line">            verbose=<span class="literal">True</span>                <span class="comment"># 显示训练进度</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练基础模型</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        base_nn.fit(X_train_scaled, y_train)</span><br><span class="line">        base_training_time = time.time() - start_time</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上进行预测</span></span><br><span class="line">        y_pred_base = base_nn.predict(X_val_scaled)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算评估指标</span></span><br><span class="line">        base_mse = mean_squared_error(y_val, y_pred_base)</span><br><span class="line">        base_rmse = np.sqrt(base_mse)</span><br><span class="line">        base_mae = mean_absolute_error(y_val, y_pred_base)</span><br><span class="line">        base_r2 = r2_score(y_val, y_pred_base)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出基础模型评估结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n基础神经网络模型评估结果:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  均方误差 (MSE): <span class="subst">&#123;base_mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  均方根误差 (RMSE): <span class="subst">&#123;base_rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  平均绝对误差 (MAE): <span class="subst">&#123;base_mae:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  R² 分数: <span class="subst">&#123;base_r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  训练时间: <span class="subst">&#123;base_training_time:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 接下来，通过网格搜索寻找最佳超参数</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n正在进行神经网络超参数调优...&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;这个过程可能需要一些时间，请耐心等待...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义参数网格</span></span><br><span class="line">        <span class="comment"># hidden_layer_sizes: 隐藏层的结构，例如(50,)表示一个隐藏层有50个神经元，(50, 25)表示两个隐藏层，分别有50和25个神经元</span></span><br><span class="line">        <span class="comment"># activation: 激活函数，常用的有&#x27;relu&#x27;、&#x27;tanh&#x27;和&#x27;logistic&#x27;</span></span><br><span class="line">        <span class="comment"># alpha: L2正则化参数，用于防止过拟合</span></span><br><span class="line">        <span class="comment"># learning_rate_init: 初始学习率，控制权重更新的步长</span></span><br><span class="line">        param_grid = &#123;</span><br><span class="line">            <span class="string">&#x27;hidden_layer_sizes&#x27;</span>: [(<span class="number">50</span>,), (<span class="number">100</span>,), (<span class="number">50</span>, <span class="number">25</span>)],  <span class="comment"># 不同的网络结构</span></span><br><span class="line">            <span class="string">&#x27;activation&#x27;</span>: [<span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;tanh&#x27;</span>],                   <span class="comment"># 不同的激活函数</span></span><br><span class="line">            <span class="string">&#x27;alpha&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>],                   <span class="comment"># 不同的正则化强度</span></span><br><span class="line">            <span class="string">&#x27;learning_rate_init&#x27;</span>: [<span class="number">0.001</span>, <span class="number">0.01</span>]               <span class="comment"># 不同的学习率</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建一个基础模型用于网格搜索</span></span><br><span class="line">        nn_model = MLPRegressor(</span><br><span class="line">            solver=<span class="string">&#x27;adam&#x27;</span>,      <span class="comment"># 使用Adam优化器</span></span><br><span class="line">            max_iter=<span class="number">500</span>,       <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">            early_stopping=<span class="literal">True</span>, <span class="comment"># 启用早停机制</span></span><br><span class="line">            validation_fraction=<span class="number">0.1</span>, <span class="comment"># 用于早停的验证集比例</span></span><br><span class="line">            tol=<span class="number">1e-4</span>,           <span class="comment"># 收敛容忍度</span></span><br><span class="line">            random_state=<span class="number">42</span>,</span><br><span class="line">            verbose=<span class="literal">False</span>       <span class="comment"># 不显示训练进度，因为GridSearchCV会训练多个模型</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用网格搜索寻找最佳参数</span></span><br><span class="line">        <span class="comment"># 注意：这里使用了较少的参数组合以减少计算时间，实际应用中可以尝试更多组合</span></span><br><span class="line">        grid_search = GridSearchCV(</span><br><span class="line">            estimator=nn_model,</span><br><span class="line">            param_grid=param_grid,</span><br><span class="line">            cv=<span class="number">3</span>,               <span class="comment"># 3折交叉验证</span></span><br><span class="line">            scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>,  <span class="comment"># 使用负MSE作为评分标准（越高越好）</span></span><br><span class="line">            n_jobs=-<span class="number">1</span>,          <span class="comment"># 使用所有可用的CPU核心</span></span><br><span class="line">            verbose=<span class="number">2</span>           <span class="comment"># 显示详细信息</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 执行网格搜索</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        grid_search.fit(X_train_scaled, y_train)</span><br><span class="line">        grid_search_time = time.time() - start_time</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取最佳参数和模型</span></span><br><span class="line">        best_params = grid_search.best_params_</span><br><span class="line">        best_model = grid_search.best_estimator_</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n网格搜索完成!&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;最佳参数: <span class="subst">&#123;best_params&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;网格搜索耗时: <span class="subst">&#123;grid_search_time:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用最佳模型在验证集上进行预测</span></span><br><span class="line">        y_pred_best = best_model.predict(X_val_scaled)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算最佳模型的评估指标</span></span><br><span class="line">        best_mse = mean_squared_error(y_val, y_pred_best)</span><br><span class="line">        best_rmse = np.sqrt(best_mse)</span><br><span class="line">        best_mae = mean_absolute_error(y_val, y_pred_best)</span><br><span class="line">        best_r2 = r2_score(y_val, y_pred_best)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出最佳模型评估结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n最佳神经网络模型评估结果:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  均方误差 (MSE): <span class="subst">&#123;best_mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  均方根误差 (RMSE): <span class="subst">&#123;best_rmse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  平均绝对误差 (MAE): <span class="subst">&#123;best_mae:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  R² 分数: <span class="subst">&#123;best_r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 可视化基础模型和最佳模型的性能比较</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n正在生成模型性能比较图...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 准备数据</span></span><br><span class="line">        models = [<span class="string">&#x27;Base Neural Network&#x27;</span>, <span class="string">&#x27;Tuned Neural Network&#x27;</span>, <span class="string">&#x27;XGBoost&#x27;</span>]</span><br><span class="line">        mse_values = [base_mse, best_mse, XGBOOST_RMSE**<span class="number">2</span>]  <span class="comment"># 由于有RMSE值，计算MSE = RMSE^2</span></span><br><span class="line">        rmse_values = [base_rmse, best_rmse, XGBOOST_RMSE]</span><br><span class="line">        r2_values = [base_r2, best_r2, XGBOOST_R2]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算RMSLE (如果基础模型和最佳模型没有RMSLE，可以简单计算一个近似值)</span></span><br><span class="line">        <span class="comment"># 注意：这只是一个简单近似，实际上RMSLE的计算需要对数转换</span></span><br><span class="line">        base_rmsle = np.sqrt(np.mean(np.power(np.log1p(y_val + <span class="number">1</span>) - np.log1p(y_pred_base + <span class="number">1</span>), <span class="number">2</span>)))</span><br><span class="line">        best_rmsle = np.sqrt(np.mean(np.power(np.log1p(y_val + <span class="number">1</span>) - np.log1p(y_pred_best + <span class="number">1</span>), <span class="number">2</span>)))</span><br><span class="line">        rmsle_values = [base_rmsle, best_rmsle, XGBOOST_RMSLE]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制MSE比较图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        bars = plt.bar(models, mse_values, color=[<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>])</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络与XGBoost模型MSE比较&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;MSE Comparison: Neural Network vs XGBoost&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;MSE (越低越好)&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;MSE (Lower is better)&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        <span class="comment"># 高亮XGBoost条形</span></span><br><span class="line">        bars[<span class="number">2</span>].set_alpha(<span class="number">0.7</span>)</span><br><span class="line">        add_value_labels(plt.gca())</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;models_mse_comparison.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制RMSE比较图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        bars = plt.bar(models, rmse_values, color=[<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>])</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络与XGBoost模型RMSE比较&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;RMSE Comparison: Neural Network vs XGBoost&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;RMSE (越低越好)&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;RMSE (Lower is better)&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        <span class="comment"># 高亮XGBoost条形</span></span><br><span class="line">        bars[<span class="number">2</span>].set_alpha(<span class="number">0.7</span>)</span><br><span class="line">        add_value_labels(plt.gca())</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;models_rmse_comparison.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制R²比较图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        bars = plt.bar(models, r2_values, color=[<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>])</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络与XGBoost模型R²比较&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;R² Comparison: Neural Network vs XGBoost&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;R² (越高越好)&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;R² (Higher is better)&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        <span class="comment"># 高亮XGBoost条形</span></span><br><span class="line">        bars[<span class="number">2</span>].set_alpha(<span class="number">0.7</span>)</span><br><span class="line">        add_value_labels(plt.gca())</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;models_r2_comparison.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制RMSLE比较图</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        bars = plt.bar(models, rmsle_values, color=[<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>])</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络与XGBoost模型RMSLE比较&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;RMSLE Comparison: Neural Network vs XGBoost&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;RMSLE (越低越好)&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;RMSLE (Lower is better)&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        <span class="comment"># 高亮XGBoost条形</span></span><br><span class="line">        bars[<span class="number">2</span>].set_alpha(<span class="number">0.7</span>)</span><br><span class="line">        add_value_labels(plt.gca())</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;models_rmsle_comparison.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 可视化预测结果与实际值的对比</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 随机选择100个样本点进行可视化</span></span><br><span class="line">        sample_indices = np.random.choice(<span class="built_in">len</span>(y_val), <span class="built_in">min</span>(<span class="number">100</span>, <span class="built_in">len</span>(y_val)), replace=<span class="literal">False</span>)</span><br><span class="line">        y_val_sample = y_val.iloc[sample_indices]</span><br><span class="line">        y_pred_sample = y_pred_best[sample_indices]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制散点图</span></span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        plt.scatter(y_val_sample, y_pred_sample, alpha=<span class="number">0.7</span>)</span><br><span class="line">        plt.plot([y_val_sample.<span class="built_in">min</span>(), y_val_sample.<span class="built_in">max</span>()], [y_val_sample.<span class="built_in">min</span>(), y_val_sample.<span class="built_in">max</span>()], <span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络模型预测值与实际值对比&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Neural Network Prediction vs Actual Values&#x27;</span>,</span><br><span class="line">                        xlabel=<span class="string">&#x27;实际卡路里消耗&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Actual Calories&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;预测卡路里消耗&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Predicted Calories&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;neural_network_prediction_comparison.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 可视化残差分布</span></span><br><span class="line">        residuals = y_val - y_pred_best</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        sns.histplot(residuals, kde=<span class="literal">True</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络模型残差分布&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Neural Network Residual Distribution&#x27;</span>,</span><br><span class="line">                        xlabel=<span class="string">&#x27;残差 (实际值 - 预测值)&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Residual (Actual - Predicted)&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;频率&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">        plt.axvline(x=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;neural_network_residual_distribution.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 6. 可视化残差与预测值的关系</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        plt.scatter(y_pred_best, residuals, alpha=<span class="number">0.7</span>)</span><br><span class="line">        plt.axhline(y=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        use_chinese_font(ax, </span><br><span class="line">                        title=<span class="string">&#x27;神经网络模型残差与预测值的关系&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Neural Network Residuals vs Predicted Values&#x27;</span>,</span><br><span class="line">                        xlabel=<span class="string">&#x27;预测卡路里消耗&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Predicted Calories&#x27;</span>,</span><br><span class="line">                        ylabel=<span class="string">&#x27;残差&#x27;</span> <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE <span class="keyword">else</span> <span class="string">&#x27;Residual&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        show_figure(plt.gcf(), <span class="string">&#x27;neural_network_residual_vs_prediction.png&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存最佳模型</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;models&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;models&#x27;</span>)</span><br><span class="line">        joblib.dump(best_model, <span class="string">&#x27;models/best_nn_model.pkl&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n最佳神经网络模型已保存到: models/best_nn_model.pkl&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存特征缩放器，用于后续预测</span></span><br><span class="line">        joblib.dump(scaler, <span class="string">&#x27;models/nn_scaler.pkl&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;特征缩放器已保存到: models/nn_scaler.pkl&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_model, best_rmse, best_r2, best_rmsle</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;神经网络模型训练和评估过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成提交文件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_submission</span>(<span class="params">model, test_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用训练好的模型生成提交文件</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model: 训练好的模型</span></span><br><span class="line"><span class="string">        test_data (DataFrame): 测试数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;正在生成提交文件...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义可能的测试数据路径</span></span><br><span class="line">        possible_test_paths = [</span><br><span class="line">            <span class="string">&#x27;/kaggle/input/playground-series-s5e5/test.csv&#x27;</span>,  <span class="comment"># Kaggle路径</span></span><br><span class="line">            <span class="string">&#x27;test.csv&#x27;</span>  <span class="comment"># 本地路径</span></span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 尝试读取测试集ID</span></span><br><span class="line">        test_ids = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> path <span class="keyword">in</span> possible_test_paths:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">                    test_ids = pd.read_csv(path)[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;成功从 <span class="subst">&#123;path&#125;</span> 读取测试集ID&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;尝试从 <span class="subst">&#123;path&#125;</span> 读取测试集ID失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> test_ids <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;无法找到测试数据文件，请确保test.csv存在于正确位置&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载保存的特征缩放器</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            scaler = joblib.load(<span class="string">&#x27;models/nn_scaler.pkl&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;已加载保存的特征缩放器&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;未找到保存的特征缩放器，将创建新的缩放器&quot;</span>)</span><br><span class="line">            scaler = StandardScaler()</span><br><span class="line">            X_test_scaled = scaler.fit_transform(test_data)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用加载的scaler转换测试数据</span></span><br><span class="line">            X_test_scaled = scaler.transform(test_data)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 预测</span></span><br><span class="line">        predictions = model.predict(X_test_scaled)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 确保预测值为非负数（卡路里不可能为负）</span></span><br><span class="line">        predictions = np.maximum(predictions, <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建提交文件</span></span><br><span class="line">        submission = pd.DataFrame(&#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: test_ids,</span><br><span class="line">            <span class="string">&#x27;Calories&#x27;</span>: predictions</span><br><span class="line">        &#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存为CSV文件</span></span><br><span class="line">        submission.to_csv(<span class="string">&#x27;submission_nn.csv&#x27;</span>, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;提交文件已生成: submission_nn.csv，包含 <span class="subst">&#123;<span class="built_in">len</span>(submission)&#125;</span> 个预测结果&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示预测值的基本统计信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n预测结果统计信息:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;最小值: <span class="subst">&#123;predictions.<span class="built_in">min</span>():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;最大值: <span class="subst">&#123;predictions.<span class="built_in">max</span>():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;平均值: <span class="subst">&#123;predictions.mean():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;中位数: <span class="subst">&#123;np.median(predictions):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;标准差: <span class="subst">&#123;predictions.std():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;生成提交文件过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 直接运行主函数，不进行命令行参数解析</span></span><br><span class="line">        <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;开始执行神经网络模型训练，与XGBoost模型性能比较...&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Starting neural network model training and comparison with XGBoost model performance...&quot;</span>)</span><br><span class="line">        main(use_sampling=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;程序执行完成！&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Program execution completed!&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> CHINESE_FONTS_AVAILABLE:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;程序执行过程中出错：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error during program execution: <span class="subst">&#123;e&#125;</span>&quot;</span>) </span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528125435302.png" alt="image-20250521154842937"></p>
<p>最后还有一个报告：</p>
<p>太长了我截取一部分：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250528125654490.png" alt="image-20250528125654490"></p>
<p>说明了什么呢？<br>
一、训练过程监控<br>
Iteration 9-15<br>
loss = 6.75 → 5.65：模型预测误差逐渐减小<br>
Validation score: 0.996 → 0.997：模型在验证集上表现稳定优化<br>
二、停止训练原因<br>
连续10次迭代验证分提升不足0.0001<br>
这是防止无效训练的自动保护（类似考试连续10次成绩波动小于1分时终止复习）<br>
可能暗示当前模型已达到最佳状态<br>
三、性能评估指标<br>
指标	含义	当前值	评价标准<br>
MSE	平均平方误差	13.23	值越小越好<br>
RMSE	误差的实际量级	3.64	可比对真实数据范围<br>
MAE	平均绝对误差	2.16	忽略误差方向更直观<br>
R²	模型解释数据变化的程度	0.9966	接近1为完美拟合<br>
四、实际意义举例<br>
假设预测卡路里消耗：</p>
<p>当真实消耗是 300千卡 时：<br>
预测值可能在 300±3.64千卡 范围内（RMSE范围）<br>
模型能解释 99.66% 的数据波动（R²接近满分）<br>
总结<br>
该模型已达到极优性能（R²&gt;0.99）。训练耗时23秒属于高效范畴，适合生产环境部署。</p>
<h2 id="附录">附录</h2>
<h3 id="代码说明">代码说明</h3>
<p>本项目代码分为以下几个部分：</p>
<ol>
<li><strong>calories_prediction.py</strong>：主程序，包含数据加载、预处理、探索性分析、建模和评估</li>
<li><strong>model_optimization.py</strong>：模型优化代码，包含超参数调优和最佳模型选择</li>
</ol>
<h3 id="算法流程图">算法流程图</h3>
<p>决策树流程图</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515150503097.png" alt="image-20250515150503097"></p>
<p>随机森林：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515150549532.png" alt="image-20250515150549532"></p>
<p>XGBoost:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515150627021.png" alt="image-20250515150627021"></p>
<p>线性回归：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515150722380.png" alt="image-20250515150722380"></p>
<p>模型比较流程图</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515150818433.png" alt="image-20250515150818433"></p>
<p>提交后排名</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1blog.assets/image-20250515123850765.png" alt="image-20250515123850765"></p>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>机器学习期末设计</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://yjyrichard.github.io/posts/81c54482.html">https://yjyrichard.github.io/posts/81c54482.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>Yangjiayu</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2025-05-28</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2025-05-29</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><div class="tags-punctuation"><svg class="faa-tada icon" style="height:1.1em;width:1.1em;fill:currentColor;position:relative;top:2px;margin-right:3px" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg></div>机器学习</a></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">投喂作者</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://bilibili123.oss-cn-beijing.aliyuncs.com/about/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/about/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://bilibili123.oss-cn-beijing.aliyuncs.com/about/%E6%94%AF%E4%BB%98%E5%AE%9D.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/about/%E6%94%AF%E4%BB%98%E5%AE%9D.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.36/audio/aowu.m4a"></audio><script defer="defer" src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/b5c6903b.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/9.png" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">英语学习01-名词</div></div></a></div><div class="next-post pull-right"><a href="/posts/7ca31f7.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/4.png" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">神经网络</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:bold">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">预测锻炼期间燃烧卡路里的数据分析与建模</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%A1%AE%E5%AE%9A%E4%B8%9A%E5%8A%A1%E7%9B%AE%E6%A0%87"><span class="toc-text">一、确定业务目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-text">二、获取数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%92%8C%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90"><span class="toc-text">三、数据预处理和探索性分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">3.1 数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-text">3.2 探索性数据分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%BB%BA%E6%A8%A1%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7"><span class="toc-text">四、建模和模型评价</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%BB%BA%E6%A8%A1%E7%AD%96%E7%95%A5"><span class="toc-text">4.1 建模策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-text">4.2 模型训练与评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96"><span class="toc-text">五、模型优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-text">5.1 超参数调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E5%88%86%E6%9E%90"><span class="toc-text">5.2 特征重要性分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E4%BC%98%E5%8C%96%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83"><span class="toc-text">5.3 优化后的模型比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8"><span class="toc-text">六、模型应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E6%9C%80%E7%BB%88%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-text">6.1 最终模型选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E6%A8%A1%E5%9E%8B%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-text">6.2 模型实际应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%BB%93%E8%AE%BA"><span class="toc-text">七、数据分析结论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E4%B8%BB%E8%A6%81%E5%8F%91%E7%8E%B0"><span class="toc-text">7.1 主要发现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E6%9C%AA%E6%9D%A5%E6%94%B9%E8%BF%9B%E6%96%B9%E5%90%91"><span class="toc-text">7.2 未来改进方向</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%BA%BF%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-text">基线模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%BD%E6%B1%82%E5%8D%93%E8%B6%8A%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98-GridSearchCV"><span class="toc-text">追求卓越：超参数调优 (GridSearchCV)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E4%BD%B3%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%AF%94%E8%BE%83"><span class="toc-text">最佳模型评估与比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%85%A5%E6%B4%9E%E5%AF%9F%EF%BC%9A%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-text">深入洞察：预测结果可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98"><span class="toc-text">模型保存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95"><span class="toc-text">附录</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%AF%B4%E6%98%8E"><span class="toc-text">代码说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-text">算法流程图</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-color: transparent;"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">格言🧬</p><div class="bg-ad"><div>再看看那个光点，它就在这里，这是家园，这是我们 —— 你所爱的每一个人，你认识的一个人，你听说过的每一个人，曾经有过的每一个人，都在它上面度过他们的一生✨</div><div class="btn-xz-box"><a class="btn-xz" href="#">点击开启星辰之旅</a></div></div></div><div class="t-t-r"><p class="ft-t t-l-t">猜你想看💡</p><ul class="ft-links"><li><a href="/social/link/">我的朋友</a><a href="/comments/">留点什么</a></li><li><a href="/personal/about/">关于作者</a><a href="/archives/">文章归档</a></li><li><a href="/categories/">文章分类</a><a href="/tags/">文章标签</a></li><li><a href="/box/Gallery/">我的画廊</a><a href="/personal/bb/">我的唠叨</a></li><li><a href="/site/time/">建设进程</a><a href="/site/census/">网站统计</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">推荐友链⌛</p><div class="ft-img-group"></div></div></div><div class="copyright"><span><b>&copy;2025</b></span><span><b>&nbsp;&nbsp;By Yangjiayu</b></span></div><div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.3.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Frame-Hexo-blue.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.3.1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Theme-Butterfly-6513df.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站采用多线部署，主线路托管于Vercel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Hosted-Vercel-brightgreen.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://user.51.la/" style="margin-inline:5px" title="本站数据分析得益于51la技术支持"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Analytics-51la-3db1eb.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://icp.gov.moe/?keyword=20226665" style="margin-inline:5px" title="本站已加入萌ICP豪华套餐，萌ICP备20226665号"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/萌ICP备-20226665-fe1384.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://bitiful.dogecast.com/buckets" style="margin-inline:5px" title="本网站经Service Worker分流至缤纷云对象存储"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Bucket-缤纷云-9c62da.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://www.netdun.net/" style="margin-inline:5px" title="本站使用网盾星球提供CDN加速与防护"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/CDN-网盾星球-fff2cc.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本网站源码由Github提供存储仓库"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Source-Github-d021d6.svg" alt=""/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fa fa-paper-plane"></i><span>随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:toggleWinbox();"><i class="fas fa-cog"></i><span>美化设置</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://www.312782.xyz/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://www.312782.xyz/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script async src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="https://cdn1.tianli0.top/gh/nextapps-de/winbox/dist/winbox.bundle.min.js"></script><script async src="//at.alicdn.com/t/c/font_3586335_hsivh70x0fm.js"></script><script async src="//at.alicdn.com/t/c/font_3636804_gr02jmjr3y9.js"></script><script async src="//at.alicdn.com/t/c/font_3612150_kfv55xn3u2g.js"></script><script async src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><script defer src="/js/fomal.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax","#bibi","body > title","#app","#tag-echarts","#posts-echart","#categories-echarts"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><a class="magnet_link_more"  href="https://yjyrichard.github.io/categories/" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #e9e9e9;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--text-bg-hover)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/d522d575.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-15</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/d522d575.html&quot;);" href="javascript:void(0);" alt="">小程序起步</a><div class="blog-slider__text">初识小程序</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/d522d575.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/8610680.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/2.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-15</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/8610680.html&quot;);" href="javascript:void(0);" alt="">大模型的token究竟是啥?</a><div class="blog-slider__text">大模型的token究竟是啥?</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/8610680.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/5c2f4951.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/12.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-15</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/5c2f4951.html&quot;);" href="javascript:void(0);" alt="">基础数据结构(3)</a><div class="blog-slider__text">栈，队列，堆，二叉树</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/5c2f4951.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/45347810.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/4.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-15</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/45347810.html&quot;);" href="javascript:void(0);" alt="">基础数据结构(2)</a><div class="blog-slider__text">递归</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/45347810.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/6e192bd3.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/15.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-15</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/6e192bd3.html&quot;);" href="javascript:void(0);" alt="">基础数据结构(1)</a><div class="blog-slider__text">数组与链表</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/6e192bd3.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/3ec27523.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://bilibili123.oss-cn-beijing.aliyuncs.com/websitepic/5.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/3ec27523.html&quot;);" href="javascript:void(0);" alt="">微信支付</a><div class="blog-slider__text">java整合微信的网页支付包含原理</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/3ec27523.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" id="gitcalendarBar" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 320px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/site/census/'|| '/site/census/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("/api?null",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'null')
    }
  </script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('blog-slider swiper-container-fade swiper-container-horizontal');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('catalog_magnet');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1.5s·');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('pagination');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__jackInTheBox');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>